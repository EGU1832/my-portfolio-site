# Syllabus  

<br>

담당 조교: 조성훈 조교님  
- E.

<br>

교재:  
- `Thomas Cormen et al., Introduction to Algorithms, 4th Edition, MIT Press, 2022.`  

<br>

Schedule:  
<img src="Docs/Pasted image 20250703125755.png" width="600">
  

<br>

# 0. Introduction  

<br>

#### Algorithms: Design and Analysis  

<br>

컴퓨터 프로그램에 대해서 내가 만든 Solution이 좋고 않음을 판단하는 지표  

<br>

| 특징     | 알고리즘                  | 컴퓨터 프로그램         | 컴퓨터 시스템 |  
| ------ | --------------------- | ---------------- | ------- |  
| Nature | 추상적                   | 언어로 작성 + 실행      | HW + SW |  
| Form   | 자연어, Pesudo 코드, 플로우차트 | `.c`, `.cpp`, .. | HW, SW  |  
- 알아야할 부분은 알고리즘을 공부한다는 것이, 코딩을 한다는 것과 동의어가 아니라는 것이다.  

<br>

알고리즘의 정의는 다음과 같다:  
```
알고리즘은 어떤 값 또는 값 집합을 입력으로 받아 유한한 시간 내에 어떤 값 또는 값 집합을 출력으로 생성하는 잘 정의된 계산 절차이다.
```

<br>

알고리즘을 설계하는 과정은 다음과 같다:  
```
문제 이해 및 정의 -> 솔루션 구상 -> 알고리즘 선택 및 구체화
-> 알고리즘 분석(성능 평가) -> 구현 및 테스트
```

<br>

알고리즘의 파라다임은 다음과 같다:  
- Brute Force  
- Divide and Conquer  
- Greedy Algorithm  
- DP  

<br>

알고리즘을 분석한다는 것은 거기에 드는 리소스를 예상하는 것이다.  
- 리소스: CPU, Memory `본 수업에선 주로 CPU 사용량을 분석한다.`  

<br>

#### e.g. Insertion Sort  

<br>

문제는 다음과 같은 형태를 띄고 있다.  
<img src="Docs/Pasted image 20250624134052.png" width="450">
  

<br>

관련 알고리즘은 정말 많다.  
- Bubble, Selection, **Insertion**, Shell, **Merge**, **Heap**, **Quick**, **Counting**, **Radix,** **Bucket**  

<br>

Sorting을 한다는 것은 어차피 전체의 수를 비교해야 한다는 것이다.  
약 $`n^2`$ 만큼의 비교가 Brute Force적으로 필요하다.  
이를 줄이는 것이 Sorting Algorithm의 일이다.  

<br>

**Insertion-sort**  

<br>

정렬된 배열의 오른쪽 끝에 새 원소를 적절한 위치에 삽입하는 방식  
단순하지만 직관적이고 작은 데이터에 효과적인다.  
- Worst: $`O(n^2)`$  
- Best: $`O(n)`$  

<br>

Loop Invariant를 도입함으로써 Insertion-sort가 제대로 동작한다는 것을 증명할 수 있다.  
1. Initialization: 루프 시작 전  
2. Maintenance: 각 루프 Iteration 후  
3. Termination: 루프가 끝날 때  

<br>

#### Analyzing Algorithm  

<br>

알고리즘을 분석한다는 것은 앞서 말했듯이 실행시 드는 리소스를 예상하는 것이다.  
- 해당 강의에서는 실행 시간을 리소스로 정의한다.  
- 그리고 단일 프로세서를 가정한다.  

<br>

Insertion-sort를 분석해보자:  
<img src="Docs/Pasted image 20250624140737.png" width="450">
  
- `[1]`: for loop에서 i가 n보다 클 때를 비교하는 것 까지 합해서 n times이다. 하지만 이렇게 째째하게 따지지는 않을 것이다!  
- Best case: 이미 정렬 되어있을 때, $`an + b`$  
- Worst case: 반대로 정렬 되어있을 때, $`an^2 + bn + c`$  

<br>

거의 Worst Case의 Upper Bound를 다룬다는 것을 기억하자.  
사실상 Worst Case가 많이 일어나기 때문에 Average Case를 Strict하게 따로 가정하는 것은 많이 의미가 없다. 굳이? 싶은거다.  

<br>

Order of Growth(증가 차수): 최고 차항 빼고는 언급하지 않는다. $`an^2 + bn + c \rightarrow n^2`$  

<br>

#### Designing Algorithms  

<br>

분석하는 방법은 대충 알았다. 그럼 설계는 어떻게 할까?  

<br>

Incremental Method:  
- 입력 데이터를 하나씩 처리하면서 현재까지의 해를 점차 확장해 나가는 방식  
- e.g. Insertion Sort  

<br>

Divide and Conquer:  
- 문제를 더 작은 하위 문제로 나누고 (Divide) 각 하위 문제를 재귀적으로 해결한 뒤 (Conquer) 하위문제들의 해를 결합하여 원래 문제를 해결한다 (Combine)  
- 재귀의 형태로 대부분 동작한다.  
- e.g. Merge Sort, Quick Sort, Binary Search  

<br>

Recurrence:  
- 메모리를 많이 사용할 수 있기에 성능적으로 항상 좋은 건 아니다.  
- e.g. Factorial 계산, 피보나치 수열  

<br>

**e.g. Merge Sort**  

<br>

Divide (분할):  
- 배열 `A[p : r]`을 두 개의 부분 배열 `A[p : q]`와 `A[q + 1 : r]`로 나눈다.  
- 중간 지점 `q = ⌊(p + r) / 2⌋`를 기준으로 나눈다.  

<br>

Conquer (정복):  
- 두 개의 부분 배열을 재귀적으로 정렬한다.  
- 즉, `A[p : q]`와 `A[q + 1 : r]`에 대해 다시 Merge Sort를 호출한다.  

<br>

Combine (병합):  
- 정렬된 두 부분 배열을 하나로 병합하여 전체 정렬된 배열을 만든다  
- 병합(merge)은 추가적인 보조 배열을 사용하거나 In-place로 구현할 수 있다.  

<br>

```plaintext
MERGE-SORT(A, p, r)
1. if p ≥ r                  // 하나 이하의 원소면 정렬 불필요 → 종료
2.     return
3. q = ⌊(p + r) / 2⌋         // 중간 지점 계산
4. MERGE-SORT(A, p, q)       // 왼쪽 절반 정렬
5. MERGE-SORT(A, q + 1, r)   // 오른쪽 절반 정렬
6. MERGE(A, p, q, r)         // 정렬된 두 절반 병합
```
- 메모리를 추가로 사용하는 것을 알 수 있다.  

<br>

Merge Sort의 성능은 다음과 같다:
<br>


```math
T(n) = 
\begin{cases}
\Theta(1) \quad\quad\quad\quad\quad\quad\quad\quad\quad \text{ if } n < n_0 \\
D(n) + aT(n/b) + C(n) \quad\text{otherwise}
\end{cases}
```


```math
\begin{align}
T(n) &= \Theta(1) + 2T(n/2) + \Theta(n) \\ 
T(n) &= 2T(n/2) + \Theta(n) \\ 
T(n) &= \Theta(n\log n)
\end{align}
```

- $`\Theta(n\log n)`$ 이 도출되는 Master Theorem 과정은 후에 배운다..  
- Insertion Sort $`O(n^2)`$ 보다 비용이 적게 드는 것을 확인할 수 있다.  

<br>

#### Comparison of Representative Sorting Algorithms  

<br>

<img src="Docs/Pasted image 20250624140510.png" width="600">
  
- 이건 참고사항이다.  
- Merge Sort는 나누고 합치는 과정이 항상 필요하기 때문에 Worst Case와 Best Case의 의미가 없다.  
- 숫자 비교에서 가장 좋은 성능은 $`O(n\log n)`$ 이다.  

<br>

# 1. Characterizing Running Times  

<br>

이제 분석에 사용되는 도구에 대해서 배워보자.  
- $`O\ \ \approx\ \le`$: Upper Bound, 최악의 입력값이 들어오면 최대 이만큼 걸린다.  
- $`\Omega\ \ \approx\ \ge`$: Lower Bound, 아무리 좋은 입력값이 들어와도 최소 이만큼 걸린다.  
- $`\Theta\ \ \approx\ =`$: Tight Bound, 해당 알고리즘의 성능은 정확하게 이만큼이다.  
- $`o\ \ \approx\ <`$: Upper Bound에서 같은 경우는 제외한다.  
- $`\omega\ \ \approx\ >`$: Lower Bound에서 같은 경우는 제외한다.  
점근적 효율성: 입력값이 매우 클 때를 가정하고 성능을 분석한다.  

<br>

#### $`O`$ Notation  

<br>


```math
O(g(n)) = \{ f(n): \exists c > 0 \text{ and } n_0 \text{ such that } 0 \le f(n) \le cg(n) \text{ for all } n \ge n_0 \}
```


<br>

아무리 빨라져도 이것보단 빨라지지 않는다.  
- 최고 차항을 가지고 얘기한다.  
- 계수는 제외한다.  

<br>

상한선이기 때문에 의미적으로는 다음도 말이 된다.  
- $`f(n) = 7n^3 + 100n^2 - 20n + 6: O(n^c) \ \ \text{ for } c \ge 3`$  

<br>

#### $`\Omega`$ Notation  

<br>


```math
\Omega(g(n)) = \{ f(n): \exists c > 0 \text{ and } n_0 \text{ such that } 0 \le cg(n) \le f(n) \text{ for all } n \ge n_0 \}
```


<br>

아무리 느려져도 이것보단 느려지지 않는다.  
- 최고 차항을 가지고 얘기한다.  
- 계수는 제외한다.  

<br>

하한선이기 때문에 의미적으로는 다음도 말이 된다.  
- $`f(n) = 7n^3 + 100n^2 - 20n + 6: O(n^c) \ \ \text{ for } c \le 3`$  

<br>

#### $`\Theta`$ Notation  

<br>


```math
\Theta(g(n)) = \{ f(n): \exists c_1, c_2 > 0 \text{ and } n_0 \text{ such that } 0 \le c_1g(n) \le f(n) \le c_2g(n) \text{ for all } n \ge n_0 \}
```


<br>

$`O`$와 $`\Omega`$의 최고 차항이 같을 때
- $`O(f(n)) = \Omega(f(n))`$  
- 엄밀하게 따지면 실제 함수 자체는 살짝 다를 수 있다.  

<br>

#### e.g Insertion Sort  

<br>

$`O(n^2)`$ 라는 것은 명확하다.
Worst Case에서 Lower Bound를 정의하는 것은 꽤 Tricky 할 수 있다.  
- n이 3의 배수라고 가정하고 $`n/3`$에 해당하는 부분은 필수로 이동해야 하므로,  
- $`(n/3)(n/3) = n^2/9`$ 이기에 $`\Omega(n^2)`$ 이다.  

<br>

여기까지 하면 드는 생각이 있겠지만 왠지 허술하다(..)  
그런 것 같기도 하고 아닌 것 같기도 하고.. "대략적으로" 이정도겠다 라는 식의 정의를 하다보니 그런 것 같다.  

<br>

#### Asymptotic Notation and Running Times  

<br>

| Algorithm      | Worst              | Best               | Average            | 올바른 일반 표현 가능 여부 |  
| -------------- | ------------------ | ------------------ | ------------------ | --------------- |  
| Insertion Sort | $`\Theta(n^2)`$      | $`\Theta(n)`$        | $`\Theta(n^2)`$      | X, 상황을 명시해야 함   |  
| Merge Sort     | $`\Theta(n \log n)`$ | $`\Theta(n \log n)`$ | $`\Theta(n \log n)`$ | O               |  

<br>

#### Asymptotic Notation in Equation  

<br>

`정리 필요`  
- 우변에 있으면 "존재 한다"  
- 좌변에 있으면 "모든 경우에 대해"  

<br>

Notation에 따른 정량적 비교는 다음 그래프를 참고하자.  
<img src="Docs/Pasted image 20250624154604.png" width="300">
  

<br>

# 2. Divide-and-Conquer  

<br>

Recap: Divide and Conquer  
- 문제를 더 작은 하위 문제로 나누고 (Divide)  
- 각 하위 문제를 재귀적으로 해결한 뒤 (Conquer)  
- 하위문제들의 해를 결합하여 원래 문제를 해결한다 (Combine)  

<br>

Divide and Conquer 형태의 문제를 점화식으로 정의하고,  
그에 대한 점근해를 구하는것이 이번 강의의 목표이다.  

<br>

#### Recurrence (점화식, 재귀식)  

<br>

대표적으로는 피보나치 수열이 있다.
<br>


```math
F_n = F_{n-1} + F_{n-2}
```


<br>

Algorithmic 점화식도 있다.
<br>


```math
T(n) = 2T(n/2) + \Theta(n)
```

- 알고리즘을 위한 점화식을 적어줄 때 Base Case를 굳이 상세하게 적지 않아도 식만 있으면 된다.  
- 점화식 정의를 할 때는 꼭 필요하지 않은 이상 Ceiling이나 Floor 형태로 정의하지는 않는다.  
- Upper Bound를 명시하고 싶을 때는 부등호를 사용하기도 한다.
<br>


```math
T(n) \le 2T(n/2) + \Theta(n)
```


<br>

`7p. 수업내용이랑 강의자료랑 다름`  

<br>

#### Examples of Recurrence from Divide-and-Conquer Algorithms  

<br>

$`n\times n`$ 행렬곱을 $`n/2 \times n/2`$ 크기의 하위문제 8개로 나누었을 때

```math
T(n) = 8T(n/2) + \Theta(1) \quad \therefore T(n) = \Theta(n^3)
```


<br>

Strassen Algorithm: 위 문제를 7개의 하위 문제로 나눌 수 있도록 발전시킨 알고리즘
<br>


```math
T(n) = 7T(n/2) + \Theta(1) \quad \therefore T(n) = \Theta(n^{\log 7}) = O(n^{2.81})
```


<br>

이 말고도 하위 문제의 크기가 서로 다르게 쪼개질 수도 있다.
<br>


```math
\begin{align}
T(n) &= T(n/3) + T(2n/3) + \Theta(n) \quad \therefore T(n) = \Theta(n\log n) \\
T(n) &= T(n-1) + \Theta(1) \quad \therefore T(n) = \Theta(n)
\end{align}
```


<br>

먼저 행렬곱 문제들을 자세히 살펴보자.  

<br>

#### Multiplying Square Matrices  

<br>


```math
\mathbf{A}_{n\times n} \times \mathbf{B}_{n \times n} = \mathbf{C}_{n\times n}
```


```math
c_{ij} = \sum^{n}_{k=1}a_{ik} \cdot b_{kj}
```


<br>

i, j, k에 대하여 Loop가 돌아야 하기 때문에 $`\Theta(n^3)`$ 이라는 것은 자명하다:  
```python
Matrix-multiply(A, B, C, n)
1. for i = 1 to n
2.     for j = 1 to n
3.          for k = 1 to n
4.              c_ij = c_ij + a_ik * b_kj
```

<br>

그럼 이제 Divide-and-Conpuer를 적용해보자.  
- $`\mathbf{A}`$와 $`\mathbf{B}`$를 $`n/2\times n/2`$ 크기로 쪼갠 뒤 각각 곱하여서 $`n/2\times n/2`$ 크기의 $`\mathbf{C}`$를 연산한다.  
- 예를 들면 $`\mathbf{C}_{11}`$을 구하는 과정은 다음과 같다.
<br>


```math
\mathbf{C}_{11} = \mathbf{A}_{11} \cdot\mathbf{B}_{11} + \mathbf{A}_{12}\cdot \mathbf{B}_{21}
```

- 따라서 총 8개의 하위 문제가 생성된다.  

<br>

**Analysis**  

<br>

$`n = 1`$일 때, $`c_{11} = c_{11} + a_{11} \cdot b_{11}`$을 수행한다: $`\Theta(1)`$
$`n>1`$일 때, 
C의 값을 업데이트 하는 방식이기 때문에 따로 Combine 비용은 발생하지 않는다.  

<br>

그럼 Divide-and-Conpuer 방법을 써도 성능이 나아진 건 없다 `..`  

<br>

근데 다음 식의 최종적인 비용의 차이가 그렇게 많이 날까?
<br>

$`T(n/2)`$의 계수, 즉 하위 문제로 뻗어나가는 가지 수가 영향을 많이 미친 것이다.

```math
\begin{align}
T(n) &= 2T(n/2) + \Theta(n) \quad \therefore T(n) = \Theta(n\log n) \\
T(n) &= 8T(n/2) + \Theta(1) \quad \therefore T(n) = \Theta(n^3)
\end{align}
```


<br>

#### Strassen Algorithm  

<br>

Strassen Algorithm은 저 계수, 즉 가지 수를 줄이는 방법을 고안한 것이다.  

<br>

핵심 아이디어는 다음 식이다.
<br>


```math
\begin{align}
x^2 - y^2 &= x^2 - xy + xy - y^2 \\ 
&= x(x - y) + y(x - y) \\ 
&=(x + y)(x - y) \\
\end{align}
```

- 곱셈 수를 줄이는 방법이다.  

<br>

 $`\mathbf{A}, \mathbf{B}`$를 $`n/2\times n/2`$ 행렬로 나누는 것 까지는 앞과 똑같다.  
3. $`n/2\times n/2`$ 행렬 $`\mathbf{S}_n`$ 10개를 생성한다: $`\Theta(n^2)`$  
4. $`n/2\times n/2`$ 행렬 $`\mathbf{P}_n`$ 7개를 생성한다: $`\Theta(n^2)`$  
5. $`\mathbf{A}, \mathbf{B}`$의 Submatrix로 $`\mathbf{P}_n`$ 7개를 재귀적으로 계산한다. (Conauer): $`7T(n/2)`$  
6. $`\mathbf{P}_n`$를 잘 조합하여 $`\mathbf{C}_{11}, \mathbf{C}_{12}, \mathbf{C}_{21}, \mathbf{C}_{22}`$를 구한다: $`\Theta(n^2)`$  

<br>


```math
\begin{align}
\mathbf{C}_{11} &= P_5 + P_4 - P_2 + P_6 \\
\mathbf{C}_{12} &= P_1 + P_2 \\
\mathbf{C}_{21} &= P_3 + P_4 \\
\mathbf{C}_{22} &= P_5 + P_1 - P_3 - P_7
\end{align}
```


<br>

즉, 곱셈 연산을 거의 꼼수에 가까운 우회적 계산을 통해서 덧셈으로 대체하는 방법으로 가지 수를 8개에서 7개로 줄여서 $`O(n^{2.37286})`$으로 만든것이다.  
하지만 실제로 쓰지 않는 데는 이유가 있다:  
- Sparse Matrix에는 적합하지 않다.  
- 수치적으로 안정적이지 않다 (곱셈과 덧셈의 반복적인 교차 계산)  
- Submatrix $`\mathbf{S}, \mathbf{P}`$ 의 메모리 과소비  

<br>

#### Solving Recurrences  

<br>

점화식의 점근해를 계산하는 방법은 다음과 같은 네 가지 방법이 있다:  
1. **Substitution Method**: 추측 + 귀납 증명  
2. **Recursion-tree Method**: Tree로 시각화 후 Level 별 비용 합산  
3. **Master Method**: 정형식 $`T(n) = aT(n/b) + f(n)`$  
4. **Arka-Bassi Method**: 고급 일반화 기법  

<br>

#### (1) Substitution Method  

<br>

1. 점근해를 추측한다.  
2. 추측한 점근해를 점화식에 적용한다.  

<br>

따라서 어느정도의 직감을 요하기 때문에 경험이 축적되어야 한다.  

<br>

e.g. Merge Sort  
`강의자료 24-27p. 참고`  

<br>

요는 $`c`$와 $`n_0`$를 찾는 것이다.  

<br>

잘 추측할 수 있는 방법은 없다.  

<br>

#### (2) Recursion Trees  

<br>

`강의자료 29-34p. 참고`  
Recursion Tree Method를 이용하여 풀어보면 알겠지만,  
전체에서 Combine + Divide의 비용이 차지하는 비율이 크다.
<br>


```math
\sum^{\log_4{n}}_{i = 0}(\frac{3}{16})^i cn^2 + \Theta(n^{\log_4{3}}) < \sum^{\infty}{i = 0}(\frac{3}{16})^i cn^2 + \Theta(n^{\log_4{3}})
```


<br>

`강의자료 35p. 참고`  
모두 구한 뒤 교차증명을 하기 위해서는 Substitution Method를 사용하면 된다.  
- 추측한 해를 적용해서 식을 펼친 뒤 계수`강의자료에선 d를 찾으면 된다.  
- 해당 식을 만족시킬 수 있는 $`d`$가 존재하기만 하면 된다.  
- Base Case는 엄밀하게 증명하고 싶으면 보여주면 된다.  

<br>

**Irregular Example**  

<br>

앞선 예시에서 계산 했었던 것은 대칭적이고 균형있는 Tree였다.
<br>


```math
T(n) = T(n/3) + T(2n/3) + \Theta(n)
```

- 이와 같은 경우 뻗어나가는 Tree의 종류가 다르기 때문에 계산하는 것은 불가능하지 않으나 계산이 복잡해진다.  
- `37-38p.`는 참고 사항으로만 알아두면 된다.  

<br>

#### (3) Master Theorem  

<br>

점화식이 다음과 같은 형태를 띌 경우 기계적으로 점근식을 구할 수 있다:
<br>


```math
T(n) = aT(n/b) + f(n), \quad\text{where }  a \ge 1, b > 1
```

- e.g. Merge Sort, Matrix Multiplication, Strassen Algorithm  
- $`aT(n/b)`$: Conquer  
- $`f(n)`$: Driving Function, Divide + Combine  

<br>

Case 1:  
- 점화식을 Tree로 생각했을 때, Leaf Node들, 즉 Conquer이 더 영향력 있다. `차수가 크다`  

<br>

Case 2:  
- Conquer나 Divide + Combine이나 차이가 없다. `차수가 같다`  
- e.g. Merge Sort  

<br>

Case 3  
- Divide + Combine이 더 영향력 있다. `차수가 크다`  

<br>

**Examples**  
`강의자료 44p.` 참고  

<br>

2: $`\Theta`$ 쪽에 뭔가 Log가 붙어 있으면 Case 2이다.  

<br>

# 3. Probabilistic Analysis and Randomized Algorithms  

<br>

#### The Hiring Problem  

<br>

사실상 후보자가 무작위 순열로 주어지기 때문에,  
이 문제는 최댓값 갱신 횟수를 세는 문제와 같다.  

<br>

Uniform Random Permutation: 제한된 값들을 통해서 Permutation을 만들었을 때 각각의 Permutation이 생성뒬 확률은 동일하다.  

<br>

**무작위화 알고리즘 (Randomized Algorithm)**  

<br>

바뀐 시나리오 - 무작위화를 사용하기:  
- 입력 분포를 우리가 통제할 수 없다면, 알고리즘 안에서 직접 무작위화를 적용하여 '무작위 입력처럼' 만들자.  
- Pseudorandom-Number Generator  

<br>

무작위화 알고리즘은 다음과 같은 상황에서 유용하다:  
- 입력 데이터가 편향 될 수 있을 때  
- 적대적(Adverserial) 입력 순서 가능성이 존재 할 때  
- 평균적인 성능 분석을 위해 확률론적 모델이 필요할 때  

<br>


<br>

**Indicator Random Variable(지표 확률 변수)  

<br>

- 확률 변수 중에서도 특수한 확률 변수로, 기대값 $`\mathbf{E}[X]`$ 계산을 단순화하기 위해 자주 사용된다.  
- Lemma: 1 또는 0 만을 반환하는 함수로 표현할 수 있는 사건 $`A`$ 에 대하여, 그 기대값 $`\mathbf{E}[X]`$ 은 사건 $`A`$가 일어날 확률과 같다.  

<br>

e.g.   

<br>

# 4. Heapsort and Quicksort  

<br>

#### Sorting  

<br>

정렬 문제는 알고리즘에서 연구하는 근본적이고 실용적인 분야로, 정의는 다음과 같다.  
- Input: $`a_1, a_2, \cdots, a_n`$  
- Output: 정렬된 순열 $`a_1' \le a_2' \le \cdots \le a_n'`$  

<br>

Sorting 알고리즘에는 다음과 같은 것을이 있다:  
- Bubble, Selection, *Insertion*, Shell, *Merge*  
- Heap, Quick `4장에서 배울 것`  
- Counting, Radix, Bucket `비교 기반 X`  
비교 기반 Sorting의 최고 성능은 $`O(n\log n)`$이다.  

<br>

특정 상황에 대한 가장 빠른 Sorting 알고리즘은  
- Key와 Data에 대한 사전값,  
- 컴퓨터의 메모리 계층(캐시 및 가상 메모리),  
- 소프트웨어 환경 등 여러 요인에 따라 달라질 수 있다.  

<br>

대표적으로 Insertion과 Merge Sorting을 비교한다면 다음과 같이 비교될 수 있다:  
- Insertion: 최악의 경우 $`\Theta(n^2)`$가 걸리지만 다른 추가적 메모리를 사용하지 않는다.  
- Merge: 항상 $`\Theta(n\log n)`$정도로 성능이 좋지만 추가적 공간을 사용한다.  

<br>

Sorting 알고리즘들의 시간 복잡도를 간단히 Summary한 표이다.  
<img src="Docs/Pasted image 20250701024112.png" width="450">
  

<br>

## 4.1 Heapsort  

<br>

먼저 Heapsort를 살펴보자.  
목표는 Merge와 같이 최악의 경우에도 $`\Theta(n\log n)`$를 유지하는 것이고,  
Insertion과 같이 추가적 공간을 사용하지 않는 것이다.  

<br>

#### Heap  

<br>

<img src="Docs/Pasted image 20250701024741.png" width="200">
  
Heapsort를 알기 위해선 Heap이란 자료구조에 대하여 알아야 하며, 정의는 다음과 같다:  
- 정의: 완전 이진 트리 형태의 배열 기반 자료구조  
- Heap은 배열 기반이며, 트리 구조처럼 보인다.  
- 완전 이진 트리의 조건은 다음과 같다:  
- 마지막 Level을 제외한 모든 Level이 꽉 차 있어야 한다.  
- 마지막 Level은 왼쪽부터 채워져야 한다.  

<br>

Heap의 배열 인뎅싱 규칙:  
- 루트 노드: `A[1]`  
- 인덱스 `i`에 대해:  
- 부모: `A[⌊i/2⌋]`  
- L 자식: `A[2i]`  
- R 자식: `A[2i+1]`  
`실제 구현에선 보통 인덱스 `0`부터 시작하기 때문에 조정이 필요하다.`  

<br>

#### Max-Heap and Min-Heap  

<br>

Heap의 속성:  
- Max Heap: 부모 $`\ge`$ 자식 $`\rightarrow`$ 루트에 Max  
- Min Heap: 부모 $`\le`$ 자식 $`\rightarrow`$ 루트에 Min  

<br>

Heapsort는 **Max-Heap**을 쓴다. 핵심 연산을 알아보자.  
1. `MAX-HEAPIFY`: 특정 노드에서 시작해 Max-Heap 속성을 유지하도록 트리 구조 조정  
2. `BUILD-MAX-HEAP`: 배열을 Max-Heap으로 만드는 과정  
3. `HEAPSORT`: 추자적 공간을 사용하지 않는 Sort (In place Sort) 수행  

<br>

**Min-Heap**은 Priority Queue 구현에 자주 사용된다.  
- `MAX-HEAP-INSERT`, `MAX-HEAP-EXTRACT`, `MAX-HEAP-INCREASE-KEY`, `MAX-HEAP-MAXIMUM`  
- 위 함수들은 모두 Priority Queue 기능을 위한 연산들이다.  

<br>

#### `MAX-HEAPIFY`  

<br>

`MAX-HEAPIFY`: 어떤 노드 `i`에서 Max-Heap 속성이 깨졌을 때,  
그 노드부터 아래 방향으로 재귀적으로 조건을 복구하는 연산을 한다.  

<br>

전제  
- 왼쪽과 오른쪽 서브트리는 이미 Max-Heap이라고 가정하자.  
- 현재 노드 `i`만 자식보다 작을 수 있다.  

<br>

결과  
- `MAX-HEAPIFY(A, i)` 수행 후, `i`를 루트로 하는 서브트리는 Max-Heap이 된다.  

<br>

Pseudocode:  
``` python
MAX-HEAPIFY(A, i)
1  l = LEFT(i)
2  r = RIGHT(i)
3  if l ≤ heap-size and A[l] > A[i]   # Heap 범위 내에 존재하는지도 체크
4      largest = l
5  else
6      largest = i
7  if r ≤ heap-size and A[r] > A[largest]
8      largest = r                    # 삼각형을 이루는 세 값 중 가장 큰 값 결정
9  if largest ≠ i
10     swap A[i] <-> A[largest]
11     MAX-HEAPIFY(A, largest)        # Recursive Call
```
- 작동 방식은 다음과 같다:  
    - 왼쪽/오른쪽 자식과 비교 -> 더 큰 값을 가진 자식과 교환  
    - 교환이 일어나면 재귀 호출로 다시 아래로 내려감  

<br>

**시간 복잡도:**  
- $`O(\log ⁡n)`$ (트리의 높이만큼 내려갈 수 있다.)  
- Master Theorem에서 $`\Theta(n^{\log _b a}\log ^{k+1} n)`$ 에서 $`a = 1, k = 0`$ 이라 $`\Theta(\log n)`$이 된다.  

<br>

#### `BUILD-MAX-HEAP`  

<br>

`BUILD-MAX-HEAP`: 무작위 배열을 Max-Heap으로 변환한다.  
```python
BUILD-MAX-HEAP(A)
1  A.heap-size = length(A)
2  for i = ⌊n/2⌋ down to 1:
3      MAX-HEAPIFY(A, i)
```
- 왜 i = ⌊n/2⌋부터?  
- 그 뒤의 인덱스는 모두 리프 노드 (자식 없음, Heapify 필요 없음)  
- 위에서 아래로 MAX-HEAPIFY를 실행해야 전체 구조가 보장된다.  

<br>

e.g. `A[1:10]`  
- Leaf 노드를 제외한 `A[5], A[4], A[3], A[2], A[1]` 순서로 Heapify 실행된다.  
- 중간마다 부모-자식이 교환되며 힙 구조가 생성된다.  

<br>

**시간 복잡도:**  
- 단순 분석 (Simple bound)  
- MAX-HEAPIFY: $`O(\log n)`$  
- n개의 노드에 대해 MAX-HEAPIFY → $`O(n \log n)`$ `정확하지 않다!`  
- 정밀 분석 (Tighter analysis)  
- 대부분의 노드는 높이가 낮다. 즉, 높이 $`h`$인 노드는 많지 않다: $`\lceil \frac{n}{2^{h+1}} \rceil`$  
- 그리고 Heap의 높이는 $`\lfloor \log n \rfloor`$이다.  
- 따라서 전체 시간은 다음과 같이 구할 수 있다:
<br>


```math
\sum_{h=0}^{\lfloor \log n \rfloor} \left\lceil \frac{n}{2^{h+1}} \right\rceil \cdot O(h) = O\left( n \sum_{h=0}^{\log n} \frac{h}{2^h} \right)
```

- 이 합은 수학적으로 < 2이므로 최종 시간 복잡도는 다음과 같다:
<br>


```math
O(n)
```


<br>

#### Heapsort Algorithm  

<br>

Heapsort 순서는 다음과 같다:  
1. **BUILD-MAX-HEAP**: 입력 배열을 Max-Heap으로 만든다.  
2. **정렬 반복** (for i = n down to 2):  
    - `A[1]` (루트, 최대값)와 `A[i]`를 **교환**  
    - Heap 사이즈를 1 줄임 (i-1까지만 heap으로 봄)  
    - `MAX-HEAPIFY(A, 1)` 호출 → 다시 Max-Heap 성질 복구  
3. 위 과정을 heap size가 1이 될 때까지 반복  
이 과정에서 "최댓값을 하나씩 배열의 끝으로 보내며 정렬한다"  

<br>

이를 Psesudo Code로 나타내면 다음과 같다.  
```python
HEAPSORT(A, n)
1  BUILD-MAX-HEAP(A, n)
2  for i = n downto 2:
3      swap A[1] <-> A[i]
4      A.heap-size -= 1
5      MAX-HEAPIFY(A, 1)
```

<br>

#### Analysis  

<br>

Heapsort의 시간복잡도를 분석해보면 다음과 같다:  
- `BUILD-MAX-HEAP`: $`O(n)`$  
- 루프 n-1회 반복: $`O(n)`$  
- 루프 내 `MAX-HEAPIFY`: $`O(\log n)`$
<br>

$`\therefore O(n \log n)`$

<br>

이렇게만 보면 Heapsort가 꽤 괜찮은 알고리즘 같지만, 잘 짜여진 Quicksort가 실생활에선 좀 더 쓰인다.  

<br>

#### Priority Queue  

<br>

Priority Queue는 동적 집합 자료구조로, 각 원소는 Key(우선순위)를 가진다.  
Max-Heap으로 구현 가능하며, 다음 Operation을 지원한다:  
- `INSERT(S, x, k)`: 키가 k인 원소 x를 S에 삽입  
- `MAXIMUM(S)`: 가장 큰 키 값을 가진 원소 반환 (삭제 X)  
- `EXTRACT-MAX(S)`: 가장 큰 키 값을 가진 원소 삭제 및 반환  
- `INCREASE-KEY(S, x, k)`: 원소 x의 키를 k로 증가 (k ≥ 기존 키)  

<br>

e.g. 스케줄러에서 우선순위가 높은 작업부터 실행할 때 사용  
- 작업 삽입: `INSERT`  
- 가장 시급한 작업 실행: `EXTRACT-MAX`  

<br>

구현 방식은 다음과 같다.  
1. Handle을 이용:  
- 각 Heap 배열 요소는 해당 애플리케이션 객체를 가리키는 Pointer/Handle을 가짐  
- 반대로, 애플리케이션 객체도 자신이 Heap에서 저장된 Index를 기억함 -> 양방향 참조 가능  
- Opaque Handle(불투명 Handle): 실무에선 외부 코드에서 Handle을 접근하지 못하도록 함으로써 내부 구조를 감추는 좋은 SW를 만드는 것을 목표로 한다.  
2. Mapping Table 사용:  
    - Priority Queue 내부에 "객체 <-> Heap Index" 간 매핑 테이블 유지  
    - 객체에는 아무 정보도 저장하지 않아도 된다.  
    - 장점은 응용 객체가 Handle을 사용하지 않아도 된다는 점이고, 단점은 별도의 매핑 자료구조가 필요하다는 것이다.  
    - e.g. Hash Table 활용 (단점: 관리 필요)  

<br>

**Priority Queue Operations With Max-Heap**  

<br>

`MAX-HEAP-MAXIMUM(A)  
- 최댓값 조회 (삭제 X)  
- $`\Theta(1)`$: 루트 노드 접근만 하면 된다.  
```python
if A.heap-size < 1:
    error "heap underflow"
return A[1]
```

<br>

`MAX-HEAP-EXTRACT-MAX(A)`  
- 최댓값 추출 및 삭제  
- $`O(\log n)`$: `MAX-HEAPIFY` 1회 수행  
```python
max = MAX-HEAP-MAXIMUM(A)      # 루트(A[1])를 최댓값으로 저장    
A[1] = A[A.heap-size]          # 마지막 노드를 루트로 이동
A.heap-size = A.heap-size - 1  # heap-size를 1 감소
MAX-HEAPIFY(A, 1)              # Max-Heap 속성 복구    
return max                     # 최댓값 반환
```

<br>

`MAX-HEAP-INCREASE-KEY(A, x, k)`  
- Heap 내의 원소의 우선순위를 올림 (키 값을 증가)  
- $`O(\log n)`$: 루트까지 최대 $`\log n`$ 단계 상승 가능  
```python
1  if k < x.key        # 새 키값이 기존 키보다 작으면 오류 (Heap에서는 증가만 허용)
2      error “new key is smaller than current key”
3  x.key = k           # x의 키값을 k로 갱신
4  find the index i in array A where object x occurs
	# A에서 x의 Index 구하기 (예: heap 내부 탐색 or 별도 mapping 사용)
5  while i > 1 and A[PARENT(i)].key < A[i].key:
    # i가 루트가 아니고, 부모 키값이 현재 키값보다 작다면 위로 이동 필요
6      exchange A[i] with A[PARENT(i)],
        # 부모와 현재 노드 교환 (힙 상에서 위로 bubble-up)
        # 동시에 객체 ↔ 인덱스 매핑 정보도 갱신 필요
7      i = PARENT(i)
        # 인덱스를 부모로 갱신하고 루프 반복
```
1. 새 키값 `k`가 현재 키값 이상인지 확인  
2. 해당 노드의 키를 `k`로 변경  
3. 부모와 비교하며 올라가면서 (`while`) Max-Heap 속성 복구  

<br>

`MAX-HEAP-INSERT(A, x, n)`  
- 새 원소 삽입  
- $`O(\log n)`$: 실질적으로 `Increase-Key` 비용  
```python
1  if A.heap-size == n              # 힙이 가득 찼으면 더 이상 삽입 불가 (오버플로우)
2      error “heap overflow”
3  A.heap-size = A.heap-size + 1    # 새 노드를 위한 공간 확보 (사이즈 증가)
4  k = x.key                        # 새로 넣을 원소의 원래 키값 저장
5  x.key = -∞                       # 임시로 키를 -∞로 설정 (힙의 가장 아래로 들어가도록)
6  A[A.heap-size] = x               # 배열의 맨 끝 (새로 늘어난 부분)에 삽입
7  map x to index heap-size in the array # 객체 x ↔ 인덱스 heap-size 간의 매핑 정보 등록
8  MAX-HEAP-INCREASE-KEY(A, x, k)   # 실제 원하는 키값 k로 올리면서 Max-Heap 성질 복구
```
1. `heap-size`를 1 증가  
2. 마지막 위치에 key가 $`-\infty`$ 인 새 원소 삽입  
3. `MAX-HEAP-INCREASE-KEY`를 이용하여 원래 키로 설정하고 적절한 위치로 이동  

<br>

**Summery**  

<br>

| 연산                      | 시간 복잡도        |  
| ----------------------- | ------------- |  
| `MAX-HEAPIFY`           | $`O(\log n)`$   |  
| `BUILD-MAX-HEAP`        | $`O(n)`$        |  
| `HEAPSORT`              | $`O(n \log n)`$ |  
| `MAX-HEAP-MAXIMUM`      | $`\Theta(1)`$   |  
| `MAX-HEAP-EXTRACT-MAX`  | $`O(\log n)`$   |  
| `MAX-HEAP-INCREASE-KEY` | $`O(\log n)`$   |  
| `MAX-HEAP-INSERT`       | $`O(\log n)`$   |  

<br>

## 4.2 Quicksort  

<br>

이제 Quicksort를 살펴보자. 목표는 다음과 같다:  
- Worst Case 시간 복잡도는 $`\Theta(n^2)`$  
- 모든 요소가 서로 다르다고 가정할 때 Average 시간 복잡도가 $`\Theta(n \log n)`$  
- 실제 실행 시간에 영향을 주는 상수 계수(constant factor) 들이 작아서 빠르다.  
- Sort in Place 즉, 추가 메모리가 거의 필요 없다.  

<br>

Quicksort는 Divide and Conquer 전략을 따른다. Subarray $`A[p:r]`$을 정렬한다고 했을때:  
1. **Divide:**  
    - 배열 $`A[p : r]`$을 Pivot 기준으로 두 부분으로 나눔  
    - PARTITION 절차를 통해 Pivot보다 작거나 같은 값, 큰 값으로 분할  
    - Pivot은 위치 $`q`$에 저장됨  
    - 분할된 구간:  
        - 왼쪽: $`A[p : q-1]`$  
        - 오른쪽: $`A[q+1 : r]`$  
2. **Conquer**:  
    - 왼쪽과 오른쪽 부분 배열에 대해 각각 재귀적으로 QUICKSORT 실행  
3. **Combine**:  
    - 정렬이 In-place로 이루어졌기 때문에 아무것도 하지 않는다.  

<br>

Quicksort의 Pseudo Code는 다음과 같다:  
```python
QUICKSORT(A, p, r)
1  if p < r:                              # 구간이 최소 2개 이상일 때만 실행
2      q = PARTITION(A, p, r)             # 피벗 기준으로 나누고, 피벗 위치 q 반환
3      QUICKSORT(A, p, q - 1)             # 왼쪽 부분 (작은 값들) 재귀 정렬
4      QUICKSORT(A, q + 1, r)             # 오른쪽 부분 (큰 값들) 재귀 정렬
```
- 초기 호출은 `QUICKSORT(A, 1, n)` 또는 0-based면 `QUICKSORT(A, 0, n - 1)`  
- Pivot을 `PARTITION` 함수가 선택하고 제자리로 이동시킴  
- 정렬 범위를 좁혀가며 재귀적으로 수행  

<br>

`PARTITION(A, p, r)`  
- 배열 구간 $`A[p : r]`$을 Pivot을 기준으로 두 그룹으로 나눈다:  
- L: Pivot보다 작거나 같은 값  
- R: Pivot보다 큰 값  
- $`\Theta(n)`$: 전체 반복은 $`r - p`$ 번이다.  
```python
1   x = A[r]                     # Pivot: 항상 오른쪽 끝 원소 선택
2   i = p - 1                    # 작거나 같은 값들이 놓일 위치 (왼쪽 영역의 마지막 Index)
3   for j = p to r - 1:          # Pivot 제외한 구간을 순회
4       if A[j] <= x:            # 현재 값이 Pivot 이하이면
5           i = i + 1            # 왼쪽 영역 확장
6           exchange A[i] with A[j]   # 현재 값을 왼쪽 영역 끝으로 이동
7   exchange A[i + 1] with A[r]  # Pivot을 왼쪽 영역 끝 다음 위치로 이동
8   return i + 1                 # Pivot의 최종 위치 반환
```
- 루프 내에서는 Pivot보다 작거나 같은 값들을 앞쪽(i까지) 으로 옮김  
- 그 후 Pivot을 그 바로 뒤(i+1)에 위치시켜 정확한 제자리로 이동  
- 반환값 `i+1`은 Pivot의 최종 위치 -> Quicksort는 이를 기준으로 재귀 호출  

<br>

`PARTITION(A, p r)`의 Loop Invariant:  
아직 검사하지 않은 값들을 $`A[j:r - 1]`$이라고 했을 때,  
1. $`A[p:i] \le`$ Pivot  
2. $`A[i+1:j-1] >`$ Pivot  
3. $`A[r] =`$ Pivot  
마지막에 Pivot을 $`A[i+1]`$로 옮기면서 정렬 기준을 완성한다.  

<br>

#### Analysis  

<br>

**Worst Case** 일때는 `PARTITION`이 매우 불균형하게 일어날 때이다.  
- e.g. 항상 최소/최대값을 Pivot으로 선택해서 한 쪽 서브배열이 `n-1`, 다른 쪽은 `0`  
- 즉, Pivot이 맨 앞 또는 맨 끝에 놓여 Pivot 기준으로 한쪽만 남는다.  

<br>

이때 점화식을 유도하면 다음과 같다:
<br>


```math
\begin{align}
T(n) &= T(n-1) + T(0) + \Theta(n) \\
&= T(n-1) + \Theta(n) \\
&= \Theta(n^2)
\end{align}
```

- Insertion Sort와 같은 시간 복잡도를 보인다..  

<br>

**Base Case** 일때는 `PARTITION`이 항상 완전히 균형 있게 분할되는 경우이다.  
- e.g. Pivot이 항상 정확히 가운데 값을 선택  
- 각 단계마다 정확히 절반씩 나뉘는 이상적인 상황  

<br>

이때 점화식을 유도하면 다음과 같다:
<br>


```math
\begin{align}
T(n) &= 2T(n/2) + \Theta(n) \\ 
&= \Theta(n\log n)
\end{align}
```

- Master Therem으로 풀 수 있으며, Merge Sort와 동일한 구조의 점화식을 가진다.  

<br>

비록 `PARTITION`이 항상 완벽하게 균등하게 나뉘지 않아도 대체로 불균형하더라도 심하게 나쁘지 않은 분할이 자주 일어나, Quicksort의 평균 성능은 Worst Case 보다 훨씬 더 좋다.  
`PARTITION`이 항상 9:1 분할을 만든다고 가정하고 다음 식을 살펴보자:
<br>


```math
\begin{align}
T(n) &\le T(9n/10) + T(n/10) + \Theta(n) \\
&= O(n \log n)
\end{align}
```


<br>

직전에서 봤듯이, 한 번 안 좋은 `PARTITION`이 들어가도 "상수 레벨" 차이만 생길 뿐 전체 성능은 유지된다.  
전체적으로 처리할 Subarray의 수는 동일하다.  

<br>

**Randomized Quicksort**  

<br>

희박한 확률로 일어날 Worst도 방지하기 위해서 우리는 이 방법을 사용한다.  
입력이 정렬되어 있는 경우, Pivot이 맨 끝이면 항상 최악의 분할이 발생한다. $`\Theta(n^2)`$  

<br>

Randomized Quicksort: `PARTITION`에 들어가기 전, Pivot을 무작위로 선택한다.  
- 배열 내 임의의 Index를 `A[r]`과 교환 -> `PARTITION(A, p, r)`은 그대로 사용 가능  
```python
RANDOMIZED-PARTITION(A, p, r)
1   i = RANDOM(p, r)           # pivot 랜덤 선택
2   exchange A[r] with A[i]    # 맨 뒤로 이동시켜 partition과 동일하게 처리
3   return PARTITION(A, p, r)
```
- 이렇게 하면 어떤 배열이 들어와도 Worst Case 발생 확률이 매우 낮아진다.  
- $`\therefore \Theta(n\log n)`$  

<br>

#### Analysis - Average Case  

<br>

가정:  
- 정렬되는 모든 값이 서로 다르다고 가정  
- 주요 비용은 `PARTITION`이고, Pivot은 항항 무작위로 선택된다. `RANDOMIZED-PARTITION`  
- 선택된 Pivot들은 향후 고려 사항에서 제외되기에 `PARTITION`은 최대 $`n`$번 호출된다.  

<br>

분석 방법:  
- 총 비교 횟수 $`X`$를 랜덤 변수로 두고, 기대값 $`\mathbf{E}[X]`$를 구한다.  
- 한 번의 `PARTITION` 당 비교는 $`O(n)`$, 최대 $`n`$번 호출 -> 전체는 $`O(n + X)`$  

<br>

표기 정의:  
- 입력 배열을 정렬 순서로 재 정의한다: $`z_1, z_2, \dots, z_n`$  
- $`Z_{ij} = \{ z_i, z_i+1, \dots, z_j \}`$: $`z_i`$와 $`z_j`$ 사이의 모든 원소 집합  
- $`X_{ij} = \mathbf{I}[z_i \text{ is compared with }z_j ]`$: 지시 함수, 비교가 이루어졌으면 1, 아니면 0  
여기서 각 쌍 $`(z_i, z_j)`$는 최대 한 번만 비교된다. 왜냐하면 Pivot과 비교한 뒤 한 번 빠지면 더 이상 등장하지 않기 때문이다.  

<br>

QuickSort의 핵심 비용은 `비교(Comparison)`이다.  

<br>


<br>

# 5. Sorting in Linear Time Medians and Order Statistics  

<br>

## 5.1 Sorting in Linear Time  

<br>

#### Counting Sort  

<br>

정수 정렬 알고리즘, 값의 크기가 제한되어 있을 때 매우 효율적이다.  
입력으로 들어온 배열이 0-k까지의 값만을 가지는 n개의 숫자를 가진다.  

<br>

예제 코드:  
```python
def counting_sort(arr):
    max_val = max(arr)
    count = [0] * (max_val + 1)
    for num in arr:
        count[num] += 1

    for i in range(1, len(count)):
        count[i] += count[i - 1]

    output = [0] * len(arr)
    for num in reversed(arr):
        output[count[num]] = num
        count[num] -= 1
        
    return output
```
- 시간 복잡도: $`\Theta(n+k)`$ ($`n`$: 입력 크기, $`k`$: 값의 범위)  
- k가 굉장히 큰 값은 아니다. `해봤자 4-bit 정도?`  

<br>

**Counting Sort의 Stability**  
중요한 부분이 있는데, 똑같은 값이라 하더라도 처음 정렬된 순서대로 정렬된다는 것이다.
<br>


```math
n_1, n_2, n_3 \rightarrow n_1, n_2, n_3
```


<br>

#### Radix Sort  

<br>

Radix Sort는 자릿수별로 정렬하는 알고리즘이다.  
특이하게도 1의 자리부터 **Counting Sort**를 이용하여 정렬한다.  

<br>

Counting Sort가 "Stable"하기 때문에 1의 자리부터 정렬해도 그 다음 자리를 정렬 했을 때 더 낮은 자리가 이미 정렬되어 있는 것이다.  

<br>

Radix Sort의 정당성:  
- 만약 두 수의 자릿수 `i`가 다르다면  
- 그냥 자릿수 `i`만 보고 정렬하면 된다.  
- 만약 두 수의 자릿수 `i`가 같다면  
- 숫자들의 순서는 이전 단계에서 이미 정렬되어있다.  
- 따라서 현재 정렬이 Stable Sort면, 이전 순서가 보존된다.  

<br>

**시간 복잡도**  

<br>

시간 복잡도: $`\Theta(d(n+k))`$ ($`n`$: 입력 크기, $`d`$: 자릿수)  
- 그렇다면 $`\Theta(n)`$아닌가? 라고 생각할 수도 있겠지만, 좀 더 자세히 들여다봐야 할 필요가 있다.  
- Counting Sort를 수행할 $`k`$애 대한 정의를 새로 수행해주어야 할 필요가 있다.
<br>


```math
\Theta((b/r)\cdot (n + 2^r)) = \Theta(d\cdot(n+k))
```

- $`n`$ words  
- $`b`$ bits words  
- Break into $`r`$-bit digits $`d = \lceil b/r \rceil`$  
- $`k = 2^r - 1`$  
- 결국 $`r`$ 값을 어떻게 결정하느냐에 따라 전체적인 성능이 결정된다.  

<br>

그렇다면 $`r`$ 값을 어떻게 정해야 할까?  
- $`b < \lfloor \log n \rfloor`$ 일때, $`r = b`$ 로 한 번에 모든 비트를 처리해도 부담이 크지 않다.  
- $`b/r`$ 이 크지 않은 수준이라 $`\Theta(n)`$에 머무른다.  
- $`b \ge \lfloor \log n \rfloor`$ 일때, $`r = \lfloor \log n \rfloor`$ 정도로 잡는 게 적절하다.  
- $`r^k`$ 이 커질 수 있다. $`\Theta(bn/\log n)`$  

<br>

|항목|Radix Sort|Merge/QuickSort|  
|---|---|---|  
|반복 횟수|`⌈b/r⌉ = 2`|`log₂ n = 20`|  
|단위 작업|Counting Sort (`O(n + 2^r)`)|비교 기반 (`O(n log n)`)|  
|실제 작업|각 pass마다 census + move (2회)|비교 및 재귀 분할|  
|메모리 사용|많음 (`O(n + 2^r)`)|Merge는 `O(n)` 보조공간, Quick은 `O(log n)` stack|  

<br>

Radix Sorting의 차별점:  
- 기존의 비교 기반의 정렬과는 다른 방법으로 Key에 대한 정보를 얻을 수 있다.  
- Key를 배열 인덱스로 사용한다.  

<br>

#### Bucket Sort  

<br>

Bucket Sort는 입력 데이터가 균등하게 분포되어 있을 때 매우 효율적인 정렬 알고리즘이다.  
- 입력 데이터를 여러 개의 Bucket에 나누어 답고, 각 Bucket을 정렬한 뒤 병합하여 전체 정렬을 수행하는 알고리즘  
- 각 Bucket 안에서는 Insertion Sorting이나 Merge Sort, 똔느 Quick Sort 등을 사용한다. 본 강의에서는 Insertion Sort를 쓰고 있다.  
- 정수 뿐 아니라 부동소수점 등 연속적인 실수 값에도 잘 작동한다.  

<br>

Bucket Sort는 기대 성능이 좋지만 "운에 달렸다":  
- Bucket 하나에 너무 많은 값이 몰리지 않아야 한다.  
- Insertion Sort를 제외한 모든 부분은 $`\Theta(n)`$이 걸린다. (Bucket 초기화, 분배, 병합은 모두 선형 작업이다. 즉, 성능 병목은 Bucket 내부 정렬에서 발생한다.)  
- Bucket 당 항목 수가 일정하다면, 각 Bucket 정렬은 $`O(1)`$이 걸린다.  
- 평균적으로 각 Bucket에 1개씩만 들어갈 것으로 기대한다.  
하지만 최악의 경우로는 $`O(n^2)`$이 걸릴 수 있다. (Bucket 하나에 n개가 몰려 Insertion Sort)  

<br>

`30-31p.`는 살짝 대충 넘어감  

<br>

## 5.2 Medians and Order Statistics  

<br>

#### Simultaneous Minimum and Maximum  

<br>

n개의 숫자가 주어졌을 때 min과 max를 동시에 구하는 시간은 통상적으로 $`\Theta(2n-2) = \Theta(n)`$ 이다.  
하지만 다음 방법을 쓰면 $`\Theta(3\lfloor n/2 \rfloor)`$ 까지도 줄어든다.  
- 처음에 min과 max를 초기화  
- 남은 원소들을 쌍으로 처리:  
- 각 쌍에서 서로 비교  
- 작은 쪽은 min과 비교  
- 큰 쪽은 max와 비료  
- 총 3번의 비교 per pair  

<br>

#### Selection in Expected Linear Time  

<br>

이 알고리즘의 목표는 주어진 배열 `A[p..r]`에서 i번째로 작은 원소를 $`\Theta(n)`$ 시간에 찾는 것이다.  
- Quick Sort의 Partition 방식을 활용하되,  
- 항상 한쪽 분할만 재귀 호출하여 평균 시간 복잡도를 $`\Theta(n)`$으로 줄인다.  
- 가망이 없는 쪽은 버리는 것이다.  

<br>

`k = q - p + 1`: 버린 만큼은 제거해 준 사이즈로 i번째를 고정해주는 작업이다.  

<br>

**Worst Case**  

<br>

Quick Sort와 비슷하다.  
매번 한쪽 끝의 원소를 Pivot으로 선택하면:  
- 하나의 원소만 제외된 채 `n-1` 크기의 배열로 계속 재귀한다.  
- Quick Sort와 마찬가지로 최악의 경우 $`\Theta(n^2)`$ 이 발생한다.  

<br>

**Expected Case**  

<br>

Pivot이 항상 가운데 `[2/4-3/4]`구간에 위치한다면:  
- 적어도 1/4는 버릴 수 있다.  
- 이때 재귀식은 다음과 같다:
<br>


```math
T(n) = T(3n/4) + \Theta(n)
```

- 참고로 점근해는 $`T(n) = \Theta(n)`$이다.  

<br>

만약 Pivot이 중간값이 아닐 확률은 1/2이기 때문에, 성공 확률 1/2인 베르누이 시행인 셈이다.  
즉, 성공까지 기대 시도 횟수는 `2`라는 것이고  
- 절반의 경우는 1/4의 원소가 제거된다.  
- 나머지 절반은 한 개만 제거된다.  
- 그래서 전체 시간은 2배 느려질 수 있어도 여전히 $`\Theta(n)`$ 기대 시간은 유지된다.  

<br>

#### Selection in Worst Case Linear Time  

<br>

그렇다면 Worst Case인 경우에도 선형 시간으로 i번째 원소를 찾을 방법이 있을까?  
교재에 설명되어있는 방법은 복잡하고 길기 때문에 직관적으로만 이해해보자.  
- 전체 n개의 숫자가 들어왔을 때, 이를 5개씩 묶는다.  
- 그 중 i번째 숫자를 각각 그룹화한다.  
- 그러고 나서 5개를 정렬하고, 중간(2번째)에 정렬되어있는 값을 정렬한다. `뭔 말인지 모르겠다.`  
- 이 과정을 거치고 나면 중간 어디쯤에 있는 값으로 Pivot을 정할 수 있게 된다.  
이렇게 Worst Case 조차도 Linear하게 Selection 하는 것이 가능해진다.  

<br>

# 6. Hash Tables  

<br>

#### Overview  

<br>

많은 Application에서는 `INSERT`, `SEARCH`, `DELETE`만 지원하면 되는 Dynamic Set이 필요하다.  
이때 우리는 검색을 빠르게 하기 위해 Hash Table을 사용한다.  
Hash Table은 보통 빠르지만, 최악의 경우 선형 시간도 가능하므로 설계가 중요하다.  

<br>

Hash Table의 장점:  
- Expected Time: $`O(1)`$  
- Worst Case: $`\Theta(n)`$  

<br>

Direct Addressing:  
- Key `k`가 있을 때, 배열의 `k`번째 위치에 값을 저장하고,  
- 검색 시에도 `array[k]`만 보면 된다.  
- 하지만 Key 값 범위가 클 경우 메모리 낭비가 심하다.  

<br>

Direct Addressing이 있는데 왜 Hash Table이 필요할까?  
- 전체 Key 공간이 너무 크고, 실제 사용하는 Key의 수는 적을 떄 Hash Table을 사용한다.  
- 즉, 메모리를 절약하면서도 빠른 접근이 필요한 경우에 사용한다.  
- Hash Function을 통해 모든 Key에 대해 배열을 만들지 않고 소수의 슬롯만을 재활용한다.  
- Key `k`를 직접 인덱스로 사용하지 않고, `h(k)`라는 함수를 통해 배열의 인덱스를 계산한다.  

<br>

해시 함수의 품질과 충돌 처리 방식이 해시 테이블의 효율성을 좌우한다.  
Hash Table을 구현할 때 고려해야 할 주요 요소들:  
1. Hash Function 설계    
    → Key를 Index로 바꾸는 함수. 성능에 직결된다.  
2. 충돌 처리 방법    
    → 서로 다른 Key가 같은 Index로 해시될 경우(충돌 발생 시) 이를 어떻게 처리할지:  
    - Chaining: 같은 슬롯에 연결 리스트로 여러 원소 저장  
    - Open Addressing: 빈 슬롯을 찾아 재배치  

<br>

#### Direct-address Tables  

<br>

$`U = \{ 0, 1, \cdots, m-1 \}`$라고 하자. Direct-address Table `T`는 `T[0, ..., m-1]`이다.
- `DIRECT-ADDRESS-SEARCH(T, k)`: `return T[k]`  
- `DIRECT-ADDRESS-INSERT(T, x)`: `T[x, key] = x`  
- `DIRECT-ADDRESS-DELETE(T, x)` `T[x, key] = NIL`  
Direct-address Table은 모든 Function을 상수 시간에 처리할 수 있다.  

<br>

## 6.1 Hash Tables  

<br>

Hash Table의 기대효과:  
- 저장 공간을 $`\Theta(|K|)`$ 수준으로 줄일 수 있다.  
- 평균적으로는 $`O(1)`$ 시간에 검색이 가능하다. `Worst Case 아님`  

<br>

핵심 아이디어는 Key `k`를 그대로 Index로 사용하지 않고,  
Hash Function `h(k)`를 통해 적절한 Index로 변환해 사용하는 것이다.  

<br>

용어 정리:  
- `h`: Hash Function  
- `T`: Hash Table  
- `h: U → {0, 1, ..., m-1}`: 유효한 Index로 매핑되는 함수  
- `"k hashes to slot h(k)"`: Key k가 Hash되어 슬롯 h(k)에 저장된다.  

<br>

**Collision**  

<br>

Collision은 두 개 이상의 Key가 같은 슬롯으로 Hash되는 경우 발생한다.  
- `|K| <= m`인 경우라도, 해시 함수가 나쁘면 충돌이 여전히 발생 가능하다.  
- `|K| >= m`이면 충돌은 반드시 발생한다.  

<br>

Hash Table은 Collision을 처리할 수 있어야 하며, 대표적인 방법은 두 가지이다.:  
1. Chaining: 같은 슬롯에 여러 Key를 Linked List 등으로 저장  
2. Open Addressing: 빈 슬롯을 찾아 저장하는 방식 (예: 선형 조사, 이차 조사 등)  

<br>

Hash Table의 성능 기준은 "얼마나 잘 쪼개서 넣는가"이다.  
이상적인 Hash Function은 다음과 같이 정의할 수 있다:  
- `h(k)`가 무작위로, 균등하게, 독립적으로 `{0, 1, ..., m-1}`에서 선택  
- 한 번 `h`가 정해지면, 같은 키 `k`에 대해 `h(k)`는 항상 같은 값 반환  
- Independent Uniform Hash Function (Random Oracle): 이상적 Hash Function  
- 실제로는 구현 불가하므로 분석 모델로 사용된다.  

<br>

#### Recap: Linked List  

<br>

Hash Table의 Collision 방지를 위해서 Doubly Linked List가 쓰이며, Function은 다음과 같다:  
- `LIST-SERACHI(L, k)`  
- `LIST-PREPEND(L, x)`: Insert 할 때마다 제일 앞쪽, 즉 `L.head` 뒤에 삽입한다. 따라서 상수 시간 $`O(1)`$이 걸린다.  
- `LIST-DELETE(L, x)`: x의 포인터를 넘겨줘서 지우는 형식이기 때문에 상수 시간 $`O(1)`$에 삭제 가능하다.  

<br>

Collision 해결:  
- Insertion: Worst Case의 경우 $`O(1)`$  
- Search: Worst Case의 경우 슬롯 `h(k)`이 길이에 비례한다.  
- Deletion: Worst Case의 경우 $`O(1)`$  

<br>

#### Analysis Hashing with Chaining  

<br>

주어진 Key가 Hash Table에 있는지 검색할 때, 시간이 얼마나 걸리는가?  

<br>

**Load Factor (부하율)**  
- $`\alpha = \frac{n}{m}`$  
- $`n`$: Hash Table에 저장된 총 원소 수  
- $`m`$: 슬롯의 수 = Linked List의 수  

<br>

Collision이 날 수 있는 확률은 같은 곳에 배치될 확률이 m번 일어날 수 있기에
<br>

$`\frac1m \times \frac1m \times m = \frac1m`$ 이다.

<br>

Unsuccessful Search의 경우 Chaining을 썼을 때의 Hashing 시간복잡도는 $`\Theta(1 + \alpha)`$이다.  
- 1: Hash Funtion 자체의 동작 시간  
- $`\alpha`$: Load Factor  
Successful Search의 경우에도 마찬가지다.  
Independent Uniform Hash Function을 가정했을 때 Linked List의 Worst Case인 $`O(n)`$과는 유의미한 차이가 나는 것을 볼 수 있다.  

<br>

그렇다면 Independent Uniform Hash Function은 어떻게 만들어야 하나?  
Key가 뭐가 올지 알 수 없기 때문에 현실적으로 쉽지는 않다.  
하지만 Key 값이 $`[0, 1)`$에 위치하면 성능을 인위적으로 개선할 수 있다. `Recap: Bucket`  

<br>

현실 상황에서의 Hash Function을 개선하기 위한 가이드라인이다.  

<br>

| 키 타입      | 예시                  | 해시 함수 설계 난이도          |  
| --------- | ------------------- | --------------------- |  
| 짧은 비음수 정수 | `42`, `1023`        | 아주 쉬움                 |  
| 바이트 문자열   | `"cat"`, `"abc123"` | 쉬움 (정수 벡터로 처리 가능)     |  
| 긴 구조체나 배열 | 이미지, JSON 객체 등      | 어려움 (압축 또는 해시 전처리 필요) |  

<br>

#### Static Hashing  

<br>

한 번 정해진 고정된 해시 함수를 사용하는 방식이다.  
랜덤성(Randomization)은 키들의 분포에 의존한다. (따로 무작위 처리를 하지 않는다)  

<br>

**Division Method**
<br>


```math
h(k) = k \mod m
```

- 나눗셈 연산 1번이면 끝나기에 빠르다.  
- $`m`$은 2의 거듭제곱에 가까운 소수를 선택하는 것이 좋다. `m = 31, 97, 101 등` 공약수가 없는 소수의 성질에 따라 Collision의 가능성이 낮아지기 때문이다.  

<br>

**Multiplication Method**
<br>


```math
h(k) = \lfloor m (kA \mod 1))\rfloor
```

1. $`0<A<1`$인 실수 상수 $`A`$ 선택  
2. 키 $`k`$에 $`A`$를 곱함  
3. 소수 부분만 추출 ($`kA \mod 1 = kA - \lfloor kA \rfloor`$)  
4. 그 소수 부분에 $`m`$을 곱함  
5. 그 결과에 내림(floor) 적용  
장점은 $`m`$을 무엇을 선택해도 상관 없다는 점이지만, 아무래도 계산이 복잡해서 속도가 느릴 수 있다.  

<br>

사실 위에 소개 해준 방법이 실제로 적용하기에 좋은 방법들은 아니다.  
참고로 Multiply-Shift Method가 그나마 좋은다.  

<br>

#### Random Hashing  

<br>

공격 가능한 상황:  
- 악의적인 사용자가 Hash Function과 알고리즘을 미리 알고 있다면,    
- 의도적으로 Collision이 발생하도록 Key들을 선택해서 최악의 성능을 유도할 수 있다.  
    - 예: 모든 Key가 같은 슬롯으로 Hash되도록 선택  

<br>

해결책: 무작위 Hash Function 선택  
- Key에 의존하지 않고, Hash Function을 무작위로 선택  
- e.g. Universal Hashing  

<br>

**Unicersal Hashing**  

<br>

Hash Fucntion 집합 $`\mathcal{H}`$가 있다고 하자.    
- 각 해시 함수 $`h \in \mathcal{H}`$는 키 $`k \in U`$를 슬롯 $`\{0, 1, \dots, m-1\}`$으로 매핑한다.  
- $`\mathcal{H}`$가 Universal하다는 것은:    
    임의의 서로 다른 두 Key $`k_1, k_2 \in U`$에 대해
<br>


```math
\Pr_{h \in \mathcal{H}}[h(k_1) = h(k_2)] \le \frac{1}{m}
```

- Hash Function을 $`\mathcal{H}`$에서 무작위로 하나 선택했을 때, 두 Key가 Collision을 일으킬 확률이 균등하게 $`\frac1m`$ 이하로 제한된다.  
- 즉, Key 분포나 입력에 관계없이 Collision 확률이 작도록 보장한다.  

<br>

Hash Fucntion 집합 $`\mathcal{H}`$ 가 가질 수 있는 성질들은 다음과 같다:  

<br>

| 속성                         | 설명                                                                                                     |  
| -------------------------- | ------------------------------------------------------------------------------------------------------ |  
| **Uniform**                | 임의의 키 $`k`$와 슬롯 $`q`$에 대해 $`h(k) = q`$가 될 확률이 $`\frac1m`$                                                      |  
| **Universal**              | 임의의 두 키 $`k_1, k_2`$에 대해 $`h(k_1) = h(k_2)`$가 될 확률이 $`\le 1/m`$                                              |  
| **ε\varepsilon-universal** | $`h(k_1) = h(k_2)`$의 확률이 $`\le \varepsilon`$일 때 ($`\frac1m`$보다 완화된 조건)                                       |  
| **d-independent**          | 서로 다른 $`k_1, \dots, k_d`$와 슬롯 $`q_1, \dots, q_d`$에 대해 $`\Pr[h(k_1)=q_1, \dots, h(k_d)=q_d] = \frac{1}{m^d}`$ |  

<br>

Example: Universal Hashing Function의 정의  
`가볍게 교재 28-29p.를 참고하자.`  

<br>

#### Open Addressing  

<br>

Chaining 말고 다른 방식이다.   
- inked List를 사용하지 않는다.  
- Load Factor $`\alpha \le 1`$: Table이 가득 하면 더 이상 삽입할 수 없다.  

<br>

Insertion:  
- 아이디어는 "비어 있는 곳에 잘 넣는" 것이다.  
1. Key `k`의 첫 번째 후보 슬롯 `h(k)` 계산  
2. 해당 슬롯이 비어 있으면 삽입      
3. 아니라면 두 번째 후보 슬롯, 세 번째 후보 슬록.. 을 차례로 확인  
4. 비어 있는 슬롯 발견 시 삽입  
5. 각 Key는 자신만의 순회 순서를 가짐 (선형/이차 조사 등)  
이렇게 동작하면 너무 비효율적인거 아닌가? 그리고 `SEARCH`는 어떻게 하지?  

<br>

Searching:  
- 삽입과 거의 동일한 절차로 검색   
- 슬롯을 따라가며:  
    - 찾는 Key가 있으면 성공  
    - NIL 슬롯을 만나면 실패 (더 이상 탐색 필요 없음)  
포인터가 필요 없어 단순한 구조를 띄며, 그만큼의 공간을 Hash Table 자체에 활용 가능하다.  

<br>

**Open Addressing Searching Algorithm**  

<br>

탐색 과정 (Key `k`에 대해)  
1. $`h(k, 0)`$ 계산 → 0번째 슬롯을 검사 (이걸 probe라고 부름)  
2. 해당 슬롯이:  
    - 키 `k`를 가지고 있으면 성공  
    - `NIL`이면 실패  
    - 다른 키이면 다음 probe 위치 $`h(k, 1)`$ 확인  
3. 성공하거나, `NIL` 만날 때까지 계속  

<br>

 Probing 순서:  
- 슬롯 순회 순서는 $`\{0, 1, ..., m-1\}`$의 순열(permutation)**이어야 함  
    - 그래야 모든 슬롯을 검사할 수 있고,  
    - 슬롯 중복 검사 없이 진행 가능  

<br>

해시 함수는 다음과 같이 정의된다:
<br>


```math
h : U \times \{0, 1, \dots, m-1\} \rightarrow \{0, 1, \dots, m-1\}
```

- 즉, Key와 probe 번호를 받아 슬롯 번호로 변환  

<br>

삽입 방법  
- 검색하듯 순회하다가 처음 NIL이 나온 위치에 삽입  

<br>

Probe도 넘치면 "Hash Table Overflow"가 발생한다.  

<br>

**Pseudo Code**  

<br>

`HASH-INSERT(T, k)`:  
```plaintext
1  i = 0
2  repeat
3      q = h(k, i)                // i번째 probe 슬롯 계산
4      if T[q] == NIL             // 비어 있으면
5          T[q] = k               // 삽입
6          return q               // 위치 반환
7      else
8          i = i + 1              // 다음 슬롯 시도
9  until i == m
10 error "hash table overflow"    // m번 모두 시도했지만 삽입 실패
```
- 최대 $`m`$번 Probe 함  
- 빈 슬롯 찾으면 삽입하고 종료  
- Table이 가득 찬 경우 예외 처리  

<br>

`HASH-SEARCH(T, k)`:  
```plaintext
1  i = 0
2  repeat
3      q = h(k, i)                // i번째 probe 슬롯 계산
4      if T[q] == k               // 키 발견
5          return q               // 위치 반환
6      i = i + 1
7  until T[q] == NIL or i == m   // 비어 있는 곳 만나면 종료
8  return NIL                     // 탐색 실패
```
- 검색 도중:  
    - Key를 찾으면 바로 반환  
    - `NIL`을 만나면 더 이상 시도해볼 필요 없음 → 실패 확정  
- 최악의 경우 $`m`$번까지 확인  

<br>

**Deletion**  

<br>

`NIL`은 "여기부터는 더 이상 탐색할 필요 없다"는 강력한 종료 신호로 작용  
중간에 삭제된 슬롯이 `NIL`이 되면, 이후 키들의 검색이 끊겨버릴 수 있음  

<br>

Solution: `DELETED` 마커 사용  
- 삭제 시 슬롯을 `NIL`이 아닌 특수 값 `DELETED`**로 설정  
- 두 가지 역할을 한다.  
1. 탐색 시 (SEARCH): `DELETED`는 원하는 키가 아님 → 계속 탐색  
2. 삽입 시 (INSERT): `DELETED`는 빈 슬롯처럼 취급 → 재활용 가능  

<br>

물론 단점도 존재한다: `DELETED`가 많아지면 검색 시간이 느려진다.  
- 검색은 `NIL` 만날 때까지 계속하므로,  
- `DELETED` 슬롯이 많으면 더 많은 비교 필요  
- 결과적으로 성능이 부하율 $`\alpha`$와 무관해짐 (성능 악화)  

<br>

**Double Hashing & Linear Hashing**  

<br>

그럼 Probing은 실제로 어떻게 작동하는 것일까?  
- Independent Uniform Permutation Hashing  
- 진짜로 구현하기는 어렵다.  

<br>

| 항목       | Linear Probing                 | Double Hashing                               |  
| -------- | ------------------------------ | -------------------------------------------- |  
| 수식       | $`h(k, i) = (h'(k) + i) \mod m`$ | $`h(k, i) = (h_1(k) + i \cdot h_2(k)) \mod m`$ |  
| 충돌 처리 방식 | 고정 간격 (1칸)                     | 키마다 다른 간격                                    |  
| 장점       | 빠르고 단순                         | 충돌 분산이 뛰어남                                   |  
| 단점       | 클러스터링 심함                       | 구현 조금 복잡함                                    |  
| 탐색 시퀀스 수 | $`m`$ 개                          | 거의 $`m!`$ 개의 다양한 시퀀스 가능                        |  

<br>

Analysis of Open-address Hashing은 따로 설명하지 않으셨다.  

<br>

# 7. Dynamic Programming  

<br>

**DP(Dynamic Programming)**  

<br>

복잡한 문제를 여러 개의 작은 하위 문제(subproblem)로 나누어 이들 하위 문제의 해답을 결합하여 전체 문제의 해답을 구하는 알고리즘 설계 기법  

<br>

DP의 주요 특징은 다음과 같다.  

<br>

| 항목                                  | 설명                                                    |  
| ----------------------------------- | ----------------------------------------------------- |  
| 중복되는 하위 문제                      | 동일한 하위 문제를 여러 번 푸는 대신 한 번만 풀고 결과를 저장해서 다시 사용하는 방식 |  
| 최적 부분 구조 (Optimal Substructure) | 전체 문제의 최적 해가 하위 문제의 최적 해로부터 구성되는 구조               |  
| 탐색 대상                           | 주로 최적화 문제 (예: 최대값, 최소값, 최장 경로 등)에 사용              |  

<br>

DP의 과정은 다음과 같다.  
1. 문제의 최적해 구조를 정의  
2. 재귀적으로 최적해의 값을 정의: 수식 또는 점화식으로 표현한다.  
3. 최적해의 값을 실제로 계산 (Bottom-Up): 작은 문제부터 차례대로 계산해서 Table에 저장한다.  
- Top-Down Divide and Conquer 풀듯이 자연스럽게 정의하는 것이고,  
- Bottom-Up은 작은 문제를 기반으로 더 큰 문제를 풀어나가며 Table을 채워나가는 것이다.  
4. 필요한 경우 해 자체를 구성: 최적해의 "값"만 필요한 경우 생략 가능한다.  
- 최적화된 값은 이건데, '어떤' 최적화 과정을 거쳤느냐가 궁금할 때  

<br>

## 7.1 ROD CUTTING  

<br>

문제 상황은 다음과 같다.  
- Serling Enterprises는 긴 강철 막대를 사서 잘라 팔고 있다.  
- 각 절단은 비용이 들지 않고, 길이 i인 막대의 가격 $`p_i`$는 표로 주어진다.  
- 원하는 것은 길이 `n`인 막대를 여러 조각으로 잘라서 얻을 수 있는 최대 수익 $`r_n`$이다.  

<br>

목표는 길이 `n`인 막대를 다양한 길이의 막대로 자를 수 있는 방법 중, 총 판매 가격을 최대로 만드는 자르기 방법을 찾는 것이다.  
다음은 예시 $`p_i`$ Table이다.  

<br>

| 길이 i     | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  |  
| -------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |  
| 가격 $`p_i`$ | 1   | 5   | 8   | 9   | 10  | 17  | 17  | 20  | 24  | 30  |  

<br>

길이 `n`의 막대는 총 $`2^{n-1}`$개의 방법으로 자를 수 있다. (각 위치에서 자를지 말지 선택 가능)  
`i`길이의 막대를 하나 자르고 나머지 `n-i`에 대해 재귀적으로 해결한다.  

<br>

길이 `n`의 막대를 `k`개로 잘랐다고 했을 때, $`r_n`$은 다음과 같이 정의할 수 있다.
<br>


```math
r_n = p_{i_1} + p_{i_2} + \dots + p_{i_k}
```


<br>

점화식은 다음과 같이 정의할 수 있다.
<br>


```math
r_n = \max\{ p_n, r_1 + r_{n-1}, r_2 + r_{n-2}, \dots, r_{n-1} + r_1 \}
```

- $`p_n`$: 막대를 자르지 않고 통째로 판매했을 때의 수익  
- $`r_i + r_{n-i}`$: 길이 `i`와 `n-i`로 자른 후 각 조각의 최적 수익을 합한 값  
- 즉, 모든 자를 위치를 시도해보고 최대 수익을 선택한다.  

<br>

각 위치 i에서 첫 번째 절단을 시도:  
- 즉, 길이 `n`짜리 막대를 길이 `i`와 `n-i`로 나누어보고, 두 조각에 대해 각각 최적 수익을 더함  
- 이게 가능한 이유는 **Optimal Substructure (최적 부분 구조)** 때문이다.  
- Optimal Substructure: "하위 문제의 최적해로부터 전체 문제의 최적해를 구성할 수 있다."  
즉, 길이 `n`짜리 막대의 최적 자르기 해는 길이 `i`, `n-i`짜리 하위 문제들의 최적 해를 조합해서 만들 수 있다.  

<br>

왼쪽 조각은 자르지 않고, 오직 오른쪽 조각만 자르는 방식으로 시야를 고정하자.  
이 시각에서도 자를 수 있는 모든 경우를 고려할 수 있다.  

<br>

이를 통해 단순화된 점화식은 다음과 같다.
<br>


```math
r_n = \max_{1 \leq i \leq n}(p_i + r_{n - i})
```

- $`r_n`$: 길이 `n`에 대한 최대 수익  
- $`p_i`$: 길이 `i`의 막대 가격  
- $`r_{n-i}`$: 나머지 막대를 자른 최대 수익  
- $`r_0 = 0`$, 막대가 없으면 수익도 없다.  

<br>

### Divide-and-Conquer  

<br>

먼저 Divide-and-Conquer 방법으로 풀어보자.  

<br>

Pseudo Code는 다음과 같다.  
```python
CUT-ROD(p, n)
1	if n==0
2		return 0
3	q = -inf
4	for i = 1 to n
5		q = max{q, p[i] + CUT-ROD(p, n-i)}
6	return q
```
- 그러나 `13p.`의 Recursion Tree를 보면 알 수 있듯이, 같은 인자를 넘기는 일이 겹치며 함수가 끊임없이 호출된다. 즉, 비효율적이다.  

<br>


```math
T(0) = 1, T(n) = 1 + \sum^{n-1}_{j = 0}T(j)
```

- 참고로 이 점화식은 우리가 못푼다.  
- 하지만 계산해보면 성능이 $`T(n) = 2^n = \Theta(2^n)`$ 으로 매우 비효율적인 것을 볼 수 있다.  
- 동일한 문제를 여러번 풀기 때문이다.  

<br>

`15p. 대충 넘어감`  

<br>

### Dynamic Programming  

<br>

DP의 핵심 아이디어는 다음과 같다:  
- 중복되는 하위 문제들을 한 번만 계산하고,  
- 결과를 테이블에 저장(memoization)**하여 다시 사용할 수 있도록 함   
- 재사용 시에는 다시 계산하지 않고 저장된 값을 참조(lookup)* 한다.  
- 이 방식은 Time-Memory Trade-Off)로 볼 수 있다.  

<br>

#### Top-Down(Memoization)  

<br>

Divide-and-Conquer와 거의 비슷한데, 이미 계산 한 값을 미리 저장해두는 부분만 다르다.  
- 재귀적으로 자연스럽게 구현  
- 계산된 하위 문제의 해답은 저장해두고, 다시 필요할 때는 저장된 값을 반환  
- 저장된 값이 없을 경우에만 계산 수행 후 저장  

<br>

Pseudo Code는 다음과 같다.  
```python
MEMOIZED-CUT-ROD(p, n)
1	let r[0:n] be a new array
2	for i = 0 t0 n
3		r[i] = -inf
4	return MEMOIZED-CUT-ROD-AUX(p, n, r)

MEMOIZED-CUT-ROD-AUX(p, n, r)
1	if r[n] >= 0
2		return r[n]
3	if n==0
4		q = 0
5	else q = -inf
6		for i = 1 to n
7			q = max{q, p[i] + MEMOIZED-CUT-ROD-AUX(p, n-i, r)}
8	r[n] = q
9	return q
```

<br>

#### Bottom-up  

<br>

Bottom-up Approach로도 풀 수 있다.  
- 작은 문제부터 차례대로 계산하며 점점 큰 문제로 확장된다.  
- 어떤 문제를 풀기 전에 필요한 하위 문제들이 이미 계산되어 있다.  
- 모든 하위 문제는 한 번만 계산된다.  
- 일반적으로 상수 계수(constant factor) 측면에서 더 빠르다.  

<br>

Botton-Up 접근의 Pseudo Code는 다음과 같다.  
```python
BOTTOM-UP-CUT-ROD(p, n)
1	let r[0:n] be a new array
2	r[0] = 0
3	for j = 1 to n
4		q = -inf
5		for i = 1 to j
6			q = max{q, p[i] + r[j - i]}
7		r[j] = q
8	return r[n]
```

<br>

### Analysis  

<br>

Top-Down 방식 (`MEMOIZED-CUT-ROD`)  
- `n`개의 하위 문제 (0~n)  
- 각 하위 문제는 처음에만 계산, 그 이후는 바로 반환  
- 하지만 재귀 구조상, 한 문제 안에서 다시 `n`번 반복하므로  
- 전체 반복 횟수 = 1 + 2 + ... + n = $`\Theta(n^2)`$  

<br>

Bottom-Up 방식  
- 이중 루프 구조:  
    - 바깥 루프는 `j = 1 to n` → n번  
    - 안쪽 루프는 각 `j`마다 `i = 1 to j` → j번  
- 전체 반복 횟수 = 1 + 2 + ... + n = **$`\Theta(n^2)`$  

<br>

| 항목     | Top-down (Memoization) | Bottom-up (Tabulation) |  
| ------ | ---------------------- | ---------------------- |  
| 구현 방식  | 재귀 + Memoization       | 반복문 기반                 |  
| 코드 구조  | 자연스럽고 이해하기 쉬움          | 효율적이나 구조는 하드코딩됨        |  
| 재귀 호출  | O(n) 깊이로 발생 가능         | 없음                     |  
| 상수 계수  | 다소 느릴 수 있음             | 일반적으로 빠름               |  
| 공간 복잡도 | O(n)                   | O(n)                   |  
즉 Bottom-Up을 쓰나 Memoization을 쓰나 실제적인 성능은 동일하지만,  
Bottom-UP이 함수 호출을 덜 하기에 더 낫다.  

<br>


<br>

**Subproblem Graph**  

<br>

DP 문제들은 다음과 같은 Subproblem Graph로 나타낼 수 있다.  
<img src="Docs/Pasted image 20250703135907.png" width="100">
  
- Subproblem들이 서로 어떤 의존성을 가지는지를 나타낸 그래프로,  
- 각 노드는 특정 길이의 막대 문제 `r_n`을 의미한다.  
- 간선은 한 문제를 풀기 위해 필요한 하위 문제로 향한다.  

<br>

이제 DP의 3단계까지는 왔다.  
하지만 최대값이 아니라 철근을 '어떻게' 잘랐냐가 궁금하다면 얘기가 또 달라진다.  

<br>

다음과 같이 추가적인 정보 `s[n]`을 생성해서 출력하도록 해야한다.  
```python
EXTENDED-BOTTOM-UP-CUT-ROD(p, n)
1	let r[0:n] be a new array
2	r[0] = 0
3	for j = 1 to n
4		q = -inf
5		for i = 1 to j
6			if q < p[i] + r[j - i]      # 수정
7				q = p[i] + r[j - 1]     # 수정
8				s[j] = i                # 수정
9		r[j] = q
10	return r and s                      # 수정

PRINT-CUT-ROD-SOLUTION(p, n)
1	(r, s) = EXTEDED-BOTTOM-UP-CUT-ROD(p, n)
2	while n > 0
3		print s[n]
4		n = n - s[n]
```
- `s[j]`는 길이 `j`일 때 처음 어디서 자르면 최대 수익이 되는지를 저장한다.  

<br>

결과 Table 예시는 다음과 같다.  

<br>

|i|0|1|2|3|4|5|6|7|8|9|10|  
|---|---|---|---|---|---|---|---|---|---|---|---|  
|r[i] (최대 수익)|0|1|5|8|10|13|17|18|22|25|30|  
|s[i] (절단 위치)|-|1|2|3|2|2|6|1|2|3|10|  
예를 들어 `n = 7` 일때,  
```
| s[7] = 1 → print 1  
| n = 6  
| s[6] = 6 → print 6  
| n = 0 → 종료
```
- 결과: 1, 6 → 1 + 6 = 7   
- 즉, 1과 6으로 잘라 판매하는 것이 최대 수익이다.  

<br>

## 7.2 MATRIX-CHAIN MULTIPLICATION  

<br>

문제 상황은 다음과 같다.  
- n개의 행렬 $`<\mathbf{A_1}, \mathbf{A_2}, ..., \mathbf{A_n}>`$이 주어졌을 때, (서로 크기 다름)  
- 행렬들을 곱하는 순서를 괄호로 묶어 최소 곱셈 연산 횟수로 계산하고 싶음  
- 행렬 자체는 실제로 곱하지 않고, 곱셈 순서만 결정하는 것이 목적  

<br>

목표는 괄호 묶는 방식 (연산 순서)을 결정해서 스칼라 곱셈(scalar multiplication) 횟수를 최소화하는 것이다.  
- 행렬 $`\mathbf{A_i}`$의 크기: $`p_{i-1} \times p_i`$  
- 입력값: $`<p_0, p_1, \dots, p_i>`$  
- 계산 비용: $`\mathbf{A}(p\times q) \cdot B(q \times r) = pqr`$  
우리의 목표는 "결과 값"이 아니라 제일 적은 비용으로 곱셈을 하는 "방법"이다.  

<br>

점화식은 다음과 같이 정의할 수 있다.
<br>


```math
P(n) = \begin{cases} 1 & \text{if } n = 1 \\ \sum_{k=1}^{n-1} P(k) \cdot P(n-k) & \text{if } n \geq 2 \end{cases}
```

- 이 점화식은 우리가 풀 수는 없지만 $`P(n) = \Omega(2^n)`$ 으로, 완전탐색은 매우 비효율적이라는 결론이 나온다.  

<br>

Recap: DP의 과정  
1. 문제의 최적해 구조를 정의  
2. 재귀적으로 최적해의 값을 정의 - 수식 또는 점화식으로 표현한다.  
3. 최적해의 값을 실제로 계산 (Bottom-Up)  
4. 필요한 경우 해 자체를 구성  

<br>

일단 중요한 것은 점화식을 잘 정의하는 것이다.  
그 다음에 Top-Down이나 Botton-Up 이나 원하는 방식으로 풀 수 있다.  
- Top-Down은 직관적이지만,  
- Bottom-Up이 성능적으로 더 좋다.  

<br>

### Step 1: Stucture of an Optinal Parenthesization  

<br>

Optimal Substructure:  
- 어떤 최적의 괄호 묶기 $`\mathbf{A}_i \dots \mathbf{A}_j`$ 에서 어디선가 $`\mathbf{A}_k`$와 $`\mathbf{A}_{k+1}`$ 사이를 자른다고 하자.  
- 이때, $`\mathbf{A}_i \dots \mathbf{A}_k`$와 $`\mathbf{A}_{k+1} \dots \mathbf{A}_j`$ 각각의 괄호 묶기도 반드시 최적이어야 한다.  
즉, 문제를 두 개의 부분 문제로 나누고 각각을 독립적으로 풀 수 있으며,  
이를 결합하면 전체 문제의 최적해가 된다.  
-> Optimal Substructure  

<br>

### Step 2: A Recursion Solution  

<br>

입력값: $`<p_0, p_1, \dots, p_i>`$  
계산 비용: $`\mathbf{A}(p\times q) \cdot B(q \times r) = pqr`$  
라 했을 때,  

<br>

점화식을 정의하면 다음과 같다.
<br>


```math
m[i, j] = \begin{cases} 0 & \text{if } i = j \\ \min_{i \leq k < j} \left( m[i, k] + m[k+1, j] + p_{i-1}p_kp_j \right) & \text{if } i < j \end{cases}
```

- $`m[i, j]`$: $`\mathbf{A}_i \dots \mathbf{A}_j`$ 를 곱할 때 필요한 최소 스칼라 곱셈 수  
- $`s[i, j]`$: 최적의 k, 최적해에서 $`\mathbf{A}_i \dots \mathbf{A}_j`$ 를 어디서 자를지 나타내는 Index (괄호 위치)  
- 모든 가능한 k 위치를 시도하여 곱셈 비용이 가장 적은 split을 찾는 것이다.  

<br>

### Step 3: Computing The Optinal Costs  

<br>

하위 문제 수는 가능한 모든 $`1 \le i \le j < n`$ 쌍이기 때문에 $`\Theta(n^2)`$이다.  
하지만 ROB CUTTING 문제와 같이 중복해서 같은 문제가 여러 번 계산된다.  

<br>

Bottom-Up 방식을 이용했을 때 Pseudo Code는 다음과 같다:  
```python
MATRIX-CHAIN-ORDER(p):
1	let m[1..n, 1..n] and s[1..n - 1, 2..n] be new tables
2	for i = 1 to n
3	    m[i, i] = 0               # 하나의 행렬은 계산 필요 없음
4	for l = 2 to n:               # l: chain length
5		for i = 1 to n - l + 1
6		    j = i + l - 1
7		    m[i, j] = inf
8		    for k = i to j - 1    # 모든 k에 대해 split 시도
9			    q = m[i, k] + m[k+1, j] + p_{i-1} p_k p_j
10			    if q < m[i, j]
11			        m[i, j] = q
12			        s[i, j] = k
13	return m and s
```
- `m`: 최소 곱셈 횟수 저장  
- `s`: 그 위치에서 어디서 자르면 최적인지를 기록  

<br>


<br>

Table `m`과 `s`는 다음과 같이 구성된다.  
<img src="Docs/Pasted image 20250703150256.png" width="600">
  
- 최소 곱셈수 = 15,125  
- 자르는 방법: $`(\mathbf{A}_1(\mathbf{A}_2\mathbf{A}_3))((\mathbf{A}_4\mathbf{A}_5)\mathbf{A}_6)`$  

<br>

| 항목    | 복잡도                                         |  
| ----- | ------------------------------------------- |  
| 시간복잡도 | $`\Theta(n^3)`$ (3중 for 루프: l, i, k)          |  
| 공간복잡도 | $`\Theta(n^2)`$ (`m[i, j]`, `s[i, j]` 테이블 저장) |  

<br>

### Step 4: Constructing an Optinal Solution  

<br>

"어떻게" 잘랐는지는 다음과 같이 출력할 수 있다.  
```python
PRINT-OPTINAL-PARENS(s, i, j)
1	if i == j
2		print "A"_i
3	else print "("
4		PRINT-OPTINAL-PARENS(s, i, s[i, j])
5		PRINT-OPTINAL-PARENS(s, s[i, j] + 1, j)
6		print ")"
```
- 재귀적으로 괄호를 열고 L-R을 분할해서 출력한다.  

<br>

예를 들면 다음과 같이 출력된다.  
```
PRINT-OPTIMAL-PARENS(s, 1, 6)
-> s[1][6] = 3
-> ((A1(A2A3))((A4A5)A6))
```

<br>

# 8. Greedy Algorithms  

<br>

어떤 Optimization Problem에서는 DP보다 Greedy가 더 간단하고 효율적일 수 있다.  
Optimization Problem은 보통 일련의 단계를 거치며 각 단계에서 선택지가 존재한다.  
Greedy Algorithm은 매 단계에서 "가장 좋아보이는 선택"을 즉시 선택한다.  
- 이 방식은 Locally Optimal Choice를 선택해 Globally Optimal Solution에 도달할 수 있다고 기대하는 전략이다.  

<br>

Greedy Algorithm은 그 구조상 한계를 가지고 있으나, 장점도 있다.  
- 어떤 문제에서는 Greedy 선택이 최적해를 보장하지 않기 때문에 Greedy Algorithm이 최적해를 줄 수 있는지 여부를 사전에 확인해야한다.  
- 하지만 적절한 문제에서는 매우 강력하고 효율적인 방법이다  
- e.g. Minimum Spanning Tree Algorithms, Dijkstra's Shortest-Path Algorithms  

<br>

## 8.1 An Activity-Selection Problem  

<br>

Activity-Selection Problem은 공통 자원을 사용하는 여러 Activity 중에서 서로 겹치지 않도록 가장 많은 활동을 선택하는 것이 목표이다. `e.g. 회의실은 한 번에 하나의 활동만 할 수 있다.`  
- Activity $`S = \{a_1, a_2, \dots, a_n \}`$  
- 각 Activity $`a_i`$는 시작 시간 $`s_i`$와 종료 시간 $`f_i`$를 가진다.  
- $`0\le s_i \le f_i < \infty`$  
- Activity $`a_i`$는 $`[s_i, f_i)`$ 동안 실행된다.  
- 두 Activity $`a_i`$와 $`a_j`$는 겹치지 않으면 호환한다. 즉, $`a_i`$가 $`a_j`$ 끝나고 시작하거나 반대인 경우에만 함께 선택 가능하다.  
우리의 목효는 가능한 한 많은 호환 가능한 활동들의 Subset을 선택하는 것이 목표이다. `e.g. 가장 많은 회의를 잡기`  

<br>

일단 $`S`$의 종료 시간이 오름차순 정렬로 주어진다고 가정한다. $`f_1 \le f_2 \le \dots \le f_n`$  

<br>

| i     | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  | 11  |  
| ----- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |  
| $`s_i`$ | 1   | 3   | 0   | 5   | 5   | 6   | 8   | 8   | 2   | 12  | 12  |  
| $`f_i`$ | 4   | 5   | 6   | 7   | 9   | 10  | 11  | 12  | 14  | 16  | 16  |  
- 일단 이 표를 분석해보면 호환 가능한 Subset의 최대 크기는 4이다. e.g. $`\{ a_1, a_4, a_8, a_{11} \}`$  

<br>

### With Dynamic Programming  

<br>

일단 이 문제는 Optimal Substructure를 가지므로 DP로 해결할 수 있는 구조다.  
용어 정의를 다음과 같이 해보자.  
- $`S_{ij}`$: $`a_i`$와 $`a_j`$ 사이에서 수행될 수 있는 호환 가능한 Activity들의 집합  
- $`A_{ij}`$: Maximum $`S_{ij}`$  
- $`a_k`$: $`a_k \in A_{ij}`$  

<br>

$`a_k`$ 기준으로 두 Subproblem 들로 나눌 수 있다.
1. $`S_{ik}`$에서 찾기 즉, $`A_{ik}`$ 찾기  
2. $`S_{kj}`$에서 찾기 즉, $`A_{kj}`$ 찾기  

<br>

$`A_{ij} = A_{ik}\ \cup \ \{ a_k \} \ \cup A_{kj}`$ 이기에 다음과 같은 식을 도출 할 수 있다.

```math
|A_{ij}| = |A_{ik}| + |A_{kj}| + 1
```

- 즉, 어떤 활동 $`a_k`$를 기준으로 LR Subproblem을 최적으로 해결한 결과를 합치면 전체 문제에 대한 Solution이 된다.  

<br>

Optimal Substructure인 것은 확인했으니 점화식을 정의해보자.  
최적해의 크기를 $`c[i, j]`$ 라고 하면:
<br>


```math
c[i, j] = c[i ,k] + c[k, j] + 1
```

따라서 이를 수식으로 표현하면 다음과 같다.
<br>


```math
\begin{cases} 0 & \text{if } S_{ij} = \emptyset \\ \max \{ c[i, k] + c[k, j] + 1 : a_k \in S_{ij} \} & \text{if } S_{ij} \neq \emptyset \end{cases}
```


<br>

따라서 우리는 이를 DP로 해결할 수 있다.  
하지만 이게 최적의 방법일까?  

<br>

### With Greedy  

<br>

이 문제에서 우리는 최적해를 구하기 위해 모든 부분 문제를 다 풀 필요가 없다.  
**현재 순간에 가장 좋아 보이는 선택**만 고려하면 된다.  
- 목표는 최대한 많은 Activity를 선택하는 것.  
- 따라서 가능한 많은 다른 Activity를 남길 수 있는 선택, 즉 가장 빨리 끝나는 Activity를 먼저 선택하는 것이 합리적이다.  

<br>

이 예시 표를 보면서 생각해보자.  

<br>

| i     | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  | 11  |  
| ----- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |  
| $`s_i`$ | 1   | 3   | 0   | 5   | 5   | 6   | 8   | 8   | 2   | 12  | 12  |  
| $`f_i`$ | 4   | 5   | 6   | 7   | 9   | 10  | 11  | 12  | 14  | 16  | 16  |  
- Greedy 선택에 따라 우리는 먼제 $`a_1`$를 고를 것이다.  
- $`a_1`$를 선택한 후 남은 활동 중에서 $`a_1`$이 끝난 이후 시작되는 Activity들만 고려해야한다.  
- 즉, Subproblem은 $`S_k = \{ a_i \in S: s_i \ge f_k \}`$이다.  

<br>

만약 $`a_1`$이 최적해에 포함된다면,  
전체 최적해는 $`a_1 + S_k`$에 대한 최적해로 나늘 수 있다.  

<br>

근데 Greedy Choice가 항상 어떤 최적해의 일부일까? 라는 의문이 계속 남는다.  

<br>

#### $`\S \text{Theorem } 15.1`$  

<br>

> 어떤 Subproblem $`S_k`$에서도, 가장 빨리 끝나는 Activity $`a_m`$은 Max 호환 활동 집합에 반드시 포함될 수 있다.  

<br>

1. $`A_k`$: Max $`S_k`$  
2. $`a_j`$: $`A_k`$에서 가장 빨리 끝나는 Activity  
3. 만약 $`a_j = a_m`$, 끝  
4. 아니라면 $`a_j \neq a_m`$, $`A'_k = (A_k - \{a_j\}) \cup \{a_m\}`$로 교체  
5. $`a_m`$은 $`a_j`$보다 빨리 끝나므로, $`A_k`$의 나머지 활동들과도 호환된다.  
6. 따라서 $`A'_k`$도 최대 크기의 호환 집합이며, $`a_m`$를 포함한다.  

<br>

따라서 항상 Greedy Choice를 포함하는 최적해가 존재하므로 Greedy Strategy가 유효하다.  

<br>

### Greedy: Recursive Version  

<br>

Input은 문제 정의대로 종료 시간 기준으로 정렬되어 있어야한다.  
정렬되지 않았다면 $`O(n \log n)`$의 시간으로 정렬이 필요하다.  

<br>

Pseudo Code는 다음과 같다:  
```python
RECURSIVE-ACTIVITY-SELECTOR(s, f, k, n):
1    m = k + 1
2    while m <= n and s[m] < f[k]:
3        m = m + 1
4    if m <= n:
5        return {aₘ} ∪ RECURSIVE-ACTIVITY-SELECTOR(s, f, m, n)
6    else return ∅
```
- `s`: 시작 시간 List, `f`: 종료 시간 List  
- `k`: 마지막으로 선택한 Activity의 Index  
- Activity $`a_m`$은 $`a_k`$ 이후에 시작하는 첫 번째 호환 가능한 Activity  

<br>

선택 가능한 다음 Activity를 재귀적으로 찾고, 찾을 수 없다면 종료한다.  

<br>

시간 복잡도는 정렬되어있다고 가정하면, 각 Activity는 한 번씩만 비교되기에 $`\Theta(n)`$이다.  

<br>

재귀와 비교의 과정을 시각적으로 나타내면 다음과 같다.  
<img src="Docs/Pasted image 20250704135936.png" width="450">
  

<br>

### Greedy: Iterative Version  

<br>

역시 Input이 정렬 되어있다고 가정한다.  

<br>

Pseudo Code는 다음과 같다:  
```python
GREEDY-ACTIVITY-SELECTOR(s, f, n):
1    A = {a₁}
2    k = 1
3    for m = 2 to n:
4        if s[m] ≥ f[k]:    # 호환 가능한 활동인지 검사
5            A = A ∪ {aₘ}  # 선택
6            k = m          # 마지막 선택한 활동 갱신
7    return A
```
- 시작 Activity $`a_i`$을 선택하고, 이후 Activity들에 대해 호환 여부를 검사  
- 호환되면 선택하고, 그렇지 않으면 건너뛴다.  

<br>

시간 복잡도는 역시 $`\Theta(n)`$이다.  

<br>

## 8.2 Elements of the Greedy Strategy  

<br>

그럼 이제 예제도 봤으니, Greedy Algorithm의 개념을 알아보자.  
- Greedy Algorithm은 일련의 선택을 통해 문제에 대한 최적 해답을 구한다.  
- 매 단계에서 지금 가장 좋아 보이는 선택을 한다.  
- 항상 최적해를 보장하지는 않지만, Activity Selection Problem 같은 문제에서는 정확한 해를 제공한다.  

<br>

### Greedy-Choice Property  

<br>

Greedy-choice property란:  
- Subproblem의 결과를 고려하지 않고 현재 가장 좋아 보이는 선택만으로도 전체 최적해를 만들 수 있는 성질을 의미한다.  
- DP는 이와 달리 Subproblem의 결과를 고려해야 다음 단계로 나아갈 수 있는 구조를 띄고 있다.  

<br>

따라서 우리는 Optimal Substructure 성질 뿐만아니라, Greedy-Choice Property도 가지고 있는지 확인해야한다.  

<br>

### Exchange Argument  

<br>

Greedy Algorithm 정당성을 증명하는 방식:  
- 어떤 문제에 탐욕 알고리즘을 적용할 수 있음을 증명하려면, 그 Greedy Choice가 항상 최적해에 포함될 수 있음을 보여야 한다.  

<br>

여기서 우리는 "Exchange Argument"를 사용하며, 그 과정은 다음과 같다:  
1. 어떤 최적해가 있다고 가정한다.  
2. 그 중 최적해로의 일부 선택을 Greedy 선택으로 교체한다.  
3. 여전히 해의 크기나 질이 감소하지 않음을 보임 $`\rightarrow`$ Greedy Choice도 최적해에 포함될 수 있다.  

<br>

`21p. 대충 넘어감: Theorem 15.1의 재설명`  

<br>

### Dynamic Programming vs. Greedy  

<br>

두 방식 모두 Optimal Substructure를 활용하지만, 차이점이 있다.  

<br>

| 항목            | Dynamic Programming  | Greedy Algorithm                              |  
| ------------- | -------------------- | --------------------------------------------- |  
| Subproblem 고려 | 필요                   | 고려하지 않음                                       |  
| 속도            | 느릴 수 있다.             | 더 빠름 (보통 $`O(n)`$ 또는 $`O(n \log n)`$)             |  
| 적용 조건         | Optimal Substructure | Optimal Substructure + Greedy-choice Property |  
- Optimal Substructure가 있다고 해서 항상 Greedy Algorithm을 사용할 수 있는 것은 아니고, Greedy-choice Property가 있어야 탐욕 기법이 최적해를 보장한다.  

<br>

### e.g. The Knapsack Problems  

<br>

0-1 Knapsack Problem은 다음과 같이 정의된다.  
- 도둑이 `W` 무게 제한의 배낭에 최대 가치를 담고 싶음.  
- 각 물건은 `vᵢ` (가치), `wᵢ` (무게)를 가짐.  
- 각 아이템은 하나만 넣거나(1) 안 넣거나(0) 선택 가능.  
목표는 가치의 합이 최대가 되도록 물건 선택하는 것이다.  

<br>

Fractional Knapsack Problem (분할 가능 배낭 문제) 도 있다.  
- 조건은 동일하지만, 각 물건을 분할해서 일부만 담을 수 있음.  
- 예: 3kg짜리 물건의 절반만 담는 것이 가능  

<br>

일단 두 문제 모두 Optimal Substucture 구조를 띄기 때문에 DP로 해결 가능하다.  
어떤 무게 제한 `W`에 대해 최적해가 존재할 때,  
- 0-1의 경우: 물건 `j`를 포함한다면 남은 최적 부분은 W - wⱼ 무게 제한에서 나머지 물건으로 구성되어야 함  
- Fractional의 경우도 마찬가지로 일부 무게를 담은 경우 남은 무게에 대해 재귀적으로 최적해를 구성할 수 있음  

<br>

하지만 Greedy Strategy는 0-1 Knapsack에는 부적절하다.  
- "무게당 가치"가 높다고 무조건 먼저 넣으면, 공간 낭비로 전체 가치가 줄어들기 때문이다.  

<br>

하니만 Fractional Knapsack은 Greedy로 풀 수 있다.  
- 무게당 가치가 높은 순서로 가능한 만큼씩 담으면 항상 최적이다.  

<br>

푸는 방법은 다음과 같다:  
1. 각 아이템의 무게당 가치 `vᵢ/wᵢ` 계산  
2. 내림차순 정렬 (`O(n log n)`)    
3. 가장 높은 것부터 배낭이 허용하는 한 최대한 많이 담음  
4. 남은 공간에 다음 아이템의 일부를 담는 식으로 반복  
시간 복잡도는 $`O(n \log n)`$ 이다.  

<br>

# 9. Elementary Graph Algorithms  

<br>

## 9.1 Graph  

<br>

그래프에 대한 내용은 CSE3080(자료구조)에서 많이 배웠을 것이다.  
오늘은 그래프에 대한 Recap과 DFS, BFS에 대해서 살펴볼 것이다.  

<br>

그래프는 다양한 분야에 응용된다:  
- 전기 회로 분석 (Analysis of electrical circuits)  
- 최단 경로 탐색 (Finding shortest routes)  
- 프로젝트 계획 수립 (Project planning)  
- 언어학 (Linguistics)  
- 사회과학 (Social sciences)  
- 기타 여러 분야  

<br>

그래프 `G`는 두 집합 `V`, `E`로 구성된다.  
- `V`: 정점(vertex)의 유한하고 비어 있지 않은 집합 `ㅇ`  
- `E`: 정점 쌍들의 집합. 각 쌍은 간선(edge)이라 부른다. `-`  
따라서 그래프 `G`는 보통 `G = (V, E)`로 표현된다.  

<br>

그래프의 종류는 크게 2가지가 있다.  
- **Undirected Graph**: 정점 쌍 `(u, v)`의 순서가 없다. `(u, v) = (v, u)`  
- **Directed Graph (Digraph)**: 방향이 있는 쌍 `<u, v>`로 표현되며, `u`는 시작 정점, `v`는 도착 정점이다. `<u, v> != <v, u>`  

<br>

그래프에는 제약 사항이 있다. `간단하게 넘어감, 5p. 참고`  
- Self Loop 제한  
- Multiple Edges 제한: `본 강의에선 거의 다루지 않는다.`  

<br>

Undirected Graph에서 가능한 최대 간선 수:
<br>


```math
\frac{n(n-1)}{2}
```

- **Complete Graph**: 정점 수가 $`n`$일 때, $`\frac{n(n-1)}{2}`$개의 간선을 가지는 그래프. 즉 모든 정점 쌍이 간선으로 연결된다.  

<br>

Undirected Graph에서 $`(u, v)`$가 존재하면  
- 정점 $`u`$와 $`v`$는 Adjacent(서로 인접)하고, 간선 $`(u, v)`$는 Incident on $`u`$ and $`v`$ (부착)이다.  
Directed Graph에서 $`⟨u, v⟩`$가 존재하면  
- 정점 $`u`$는 $`v`$에 Adjacent(to)하고, 정점 $`v`$는 $`u`$에 Adjacent(from)하다.  
- 그리고 간선 $`⟨u, v⟩`$는 $`u`$와 $`v`$에 Incident 하다.  

<br>

그 외에도 Subgraph, Path, Length, Simple Path, Cycle, Connected/Unconnected, Tree와 같은 그래프와 관련된 기본적인 개념이 등장하니 잘 복기하자.  

<br>

이제 알고리즘에서 그래프를 어떻게 나타내는지 알아보자.  
그래프 $`G = (V, E)`$를 알고리즘에서 사용할 수 있게 표현하는 방법은 두 가지가 일반적이다.  
1. **Adjacency List**  
2. **Adjacency Matrix**  
- $`G`$는 Directed Graph일 수도 있고 Undirected Graph일 수도 있다.  
- 알고리즘의 시간 복잡도를 표현할 때는 $`|V|`$ (정점 수)와 $`|E|`$ (간선 수)를 기준으로 표현한다.
<br>


```math
O(V+E) = O(|V| + |E|)
```


<br>

#### Adjacency List  

<br>

$`|V|`$ 만큼의 배열 `Adi`를 갖고, 각 원소는 List이다.
- `Adj[u]`: 정점 `u`에서 직접 연결된 정점 `v`들의 List  
- `G.Adj[u]`로 표현하며, 알고리즘에서 자주 사용된다.  
- Directed와 Undirected Graph 모두에서 동작한다.  

<br>

<img src="Docs/Pasted image 20250707133316.png" width="600">
  
- 간선에 가중치 $`w`$ `(v, w)` 형태로 저장 가능  
- 공간 복잡도: $`\Theta(V+E)`$  

<br>

#### Adjacency Matrix  

<br>

<img src="Docs/Pasted image 20250707133457.png" width="300">
  
- $`|V| \times |V|`$ 크기의 행렬 $`A = (a_{ij})`$
<br>


```math
a_{ij} = \begin{cases} 1 & \text{if } (i, j) \in E \\ 0 & \text{otherwise} \end{cases}
```

- 공간 복잡도: $`\Theta(V^2)`$  
- 인접 여부를 $`O(1)`$ 시간에 확인할 수 있다.  
- 가중치 그래프의 경우 0 대신 실제 가중치를 저장 가능하다.  

<br>

| 항목             | 인접 리스트 (Adjacency List) | 인접 행렬 (Adjacency Matrix) |  
| -------------- | ----------------------- | ------------------------ |  
| **공간 복잡도**     | $`\Theta(V + E)`$         | $`\Theta(V^2)`$            |  
| **간선 탐색 속도**   | 느림 ($`O(\text{degree})`$) | 빠름 ($`O(1)`$)              |  
| **인접 정점 순회**   | 빠름                      | 느림                       |  
| **희소 그래프**에 적합 | O                       | X                        |  
| **조밀 그래프**에 적합 | X                       | O                        |  

<br>

## 9.2 Graph Operation  

<br>

그래프에서 시작 정점 `v`로부터 연결된 모든 정점을 방문하는 방법을 학습한다.  
- 대표적인 두 가지 탐색 방법은 다음과 같다:  
    1. **BFS (Breadth-First Search)**: 너비 우선 탐색  
    2. **DFS (Depth-First Search)**: 깊이 우선 탐색  
이 Search Algorithm들은 단순히 정점을 방문하는 것 외에도 다양한 정보를 생성할 수 있으며, 다양한 Graphe Algorithm의 기초가 된다.  

<br>

### 9.2.1 BFS (Breadth-First Search)  

<br>

BFS는 "파동(Wave)"처럼 퍼지며 정점들을 탐색한다.  

<br>

Input:  
- 그래프 $`G = (V, E)`$  
- 시작 정점 $`s`$  
Output:  
- $`v.d`$: 정점 $`v`$까지의 최단 거리  
- $`v.\pi`$: $`s`$로부터 최단 경로 상에서의 선행 정점 (predecessor)  
- 간선 집합 $`(u, v)`$ 중 $`v.\pi = u`$인 것들로 구성된 Subgraph는 BFS Tree를 형성한다.  

<br>

BFS의 특징은 다음과 같다.  
- FIFO Queue $`Q`$를 사용한다.  
- $`Q`$에는 항상 거리 $`k`$ 혹은 $`k+1`$인 정점들이 들어있다.  
- $`v\in Q`$: Visited && Neighbor Vertex 처리 X  

<br>

BFS의 Pseudo Code는 다음과 같다: `길긴한데 간단하니 잘 읽어보자.`  
```python
BFS(G, s)
1    for each vertex u in G.V - {s} # Initializing
2        u.color = WHITE            # 미방문
3        u.d = ∞                    # 거리 초기화
4        u.π = NIL                  # 선행 정점 없음
5    s.color = GRAY                 # 시작 정점 발견
6    s.d = 0                        # 거리 0
7    s.π = NIL
8    Q = ∅
9    ENQUEUE(Q, s) 
10   while Q ≠ ∅
11       u = DEQUEUE(Q)
12       for each v in G.Adj[u]     # 이웃 정점 순회
13           if v.color == WHITE    # 아직 발견되지 않은 경우
14              v.color = GRAY
15              v.d = u.d + 1       # 거리 1 증가
16              v.π = u             # 선행 정점 설정
17              ENQUEUE(Q, v)
18       u.color = BLACK            # 모든 이웃 처리 완료
```
- `WHITE`: 아직 방문하지 않음  
- `GRAY`: 발견되었으나 아직 이웃들을 모두 탐색하지 않음  
- `BLACK`: 이웃들도 모두 탐색 완료  
- 시간 복잡도: $`O(V+E)`$, 각 정점은 최대 한 번만 Queue에 삽입되고($`V`$), 각 간선은 Directed/Undirected Graph이냐에 따라 Queue에서 꺼내질 때 1-2번 검사된다($`E`$).  

<br>

다음은 BFS를 통해 계산된 $`v.\pi`$(Predecessor)를 이용해 정점 `s`에서 `v`까지의 최단 경로 상의 정점들을 출력하는 Pseudo Code이다:  
```python
PRINT-PATH(G, s, v)
1   if v == s
2       print s
3   else if v.π == NIL
4       print "no path from s to v exists"
5   else
6       PRINT-PATH(G, s, v.π)
7       print v
```
- Backtracking을 이용한다.  
- Recursion Call로 정방향 출력을 한다.  

<br>

### 9.2.2 DFS (Depth-First Search)  

<br>

일단 끝까지 파고들고 돌아와서 다른 방향으로 다시 탐색하는 방법이다.  

<br>

Input:  
- 그래프 $`G = (V, E)`$  
Output:  
- 두 개의 Timestamp가 각 정점에 저장된다:  
- $`v.d`$: 발견 시간 (discovery time)  
- $`v.f`$: 종료 시간 (finish time)  
- $`v.\pi`$: DFS 중에 `v`를 처음 발견하게 한 정점 (선행 정점)  
- 이때 간선 $`(u, v)`$는 Tree Edge이다.  

<br>

DFS의 동작 방식은 다음과 같다.  
- 시작점부터 모든 간선을 체계적으로 탐색한다.  
- DFS는 한 정점에서 가능한 깊이까지 들어갔다가 다시 Backtacking한다.  

<br>

Timestamp는 다음과 같은 의미를 가지고 있다:  
- 발견 시간과 종료 시간은 논리적인 탐색 순서 번호(Step Number)이며,  
- $`[1, 2|V|]`$ 의 정수 범위 내에서 각각 고유하게 부여된다.  
- $`1 \le v.d < v.f \le 2|V|`$  
이 정보로 간선 분류, 위상 정렬, Cycle 감지, 강한 연결 요소 등을 수행할 수 있다.  

<br>

DFS의 Pseudo Code는 다음과 같다:  
```python
DFS(G)
1	for each vertex u in G.V      # Initializing
2       u.color = WHITE
3       u.π = NIL
4   time = 0
5   for each vertex u in G.V
6       if u.color == WHITE
7           DFS-VISIT(G, u)       # 아직 방문되지 않은 정점에 대해 DFS-VISIT 호출

DFS-VISIT(G, u)
1   time = time + 1
2   u.d = time                     # 발견 시간 기록
3   u.color = GRAY
4   for each vertex v in G.Adj[u]
5       if v.color == WHITE
6           v.π = u
7           DFS-VISIT(G, v)
8   time = time + 1
9   u.f = time
10  u.color = BLACK                # 종료 시간 저장
```
- 시간 복잡도: $`\Theta(V+E)`$, 각 정점은 최대 한 번만 방분 되고($`V`$), 각 간선은 최대 한 번만 탐색 된다($`E`$).  

<br>

#### Parenthesis Theorem (괄호 정리)  

<br>

DFS 수행 중 기록 된 발견 시간($`v.d`$)과 종료 시간($`v.f`$)을 활용해 정점 간 관계를 판별할 수 있다.  

<br>

1. $`u.d < u.f < v.d < v.f`$: $`u`$와 $`v`$는 서로의 Parent/Descendent 관계가 아니다.  
2. $`u.d < v.d < v.f < u.f`$: $`u`$의 Descendent 중 하나가 $`v`$이다.  
3. $`v.d < u.d < u.f < v.f`$: $`v`$의 Descendent 중 하나가 $`u`$이다.  
즉, $`u.d < v.d < u.f < v.f`$는 존재 할 수 없다.  

<br>

#### Classification of Edges (DFS 간선 분류)  

<br>

DFS 중 모든 간선은 다음 네 가지 중 하나로 분류된다:  

<br>

| Type             | Definition                                 |  
| ---------------- | ------------------------------------------ |  
| **Tree Edge**    | DFS 탐색 중에 **처음** 방문하는 정점으로 가는 간선           |  
| **Back Edge**    | 현재 정점 `u`에서 자신의 조상(ancestor) `v`로 되돌아가는 간선 |  
| **Forward Edge** | `u`에서 이미 처리된 자신의 자손 `v`로 가는 간선             |  
| **Cross Edge**   | DFS 트리에서 서로 관계 없는 정점들 간의 간선                |  

<br>

#### Topological Sort (위상 정렬)  

<br>

Topological Sort of a DAG:  
- DAG(Directed Acyclic Graph)의 정점들을 간선 방향을 위배하지 않고 일렬로 정렬하는 것  

<br>

알고리즘은 다음과 같다:  
```plaintext
1. DFS(G)를 호출하여 각 정점 v의 종료 시간 v.f 계산
2. 각 정점이 종료될 때마다 List의 맨 앞에 삽입
3. List를 반환
```
- 굳이 정렬하지 않아도 종료 시간 내림차순으로 정렬된 List가 도출된다.  
- 시간 복잡도: $`\Theta(V+E)`$  

<br>


<br>

`Lemma는 보고 넘어가랜다. 43-44p. 참고`  
**$`\S`$Lemma 20.11**  
- "어떤 Directed Graph $`G`$가 Acyclic Graph라면 DFS 수행 시 Back Edge가 없어야 한다."  

<br>

**$`\S`$Lemma 20.12**  
- "DAG 상의 모든 간선 $`(u, v)`$는 DFS 수행 시 항상 `v`가 먼저 끝난다."  

<br>

# 10. Minimum Spanning Trees  

<br>

#### Overview  

<br>

**Spanning Tree**: Undirected Graph $`G = (V, E)`$에서 모든 정점을 포함하는 Tree 형태의 Subgraph, Cycle이 없어야 하고 모든 정점이 연결되어 있어야 한다.  

<br>

**Minumum Spanning Tree (MST)**: 가능한 모든 Spanning Tree 중에서 간선들의 가중치 합이 최소인 Tree이다. 하나의 Tree에서 MST는 여러 개 존재할 수 있다.  
- $`G = (V, E)`$: 그래프  
- $`w = (u, v)`$: 가중치  
- 목표는 1.모든 정점을 연결하고 2.가중치의 합이 최소가 되는 간선 집합 $`T \subseteq E`$를 찾는 것이다.  

<br>

MST는 찾는 대표 Algorithm은 2가지가 있다:  
1. **Kruskal's Algotrithm**  
- Disjoint Set 사용  
- 간선을 가중치 기준으로 오름차순 정렬 후, Cycle이 생기지 않는 간선을 하나씩 선택  
- $`O(E\lg V)`$  
2. **Prim's Algorithm**  
- Priority Queue (Binary Heap) 사용  
- 시작 정점에서부터 연결된 가장 가중치가 낮은 간선을 선택하며 확장  
- $`O(E + V\lg V)`$  
참고로 둘 모두 Greedy Algorithm이다.  

<br>

## 10.1 Building MST Alrogithm  

<br>

MST의 성질을 먼저 살펴보자.  
- 간선 수: $`|V| - 1`$  
- Cycle: None  
- Not Unique  
우리는 정점보다는 **간선** 중심으로 생각할 것이다.
<br>

$`(u, v)`$가 간선을 때, $`u`$와 $`v`$는 그 간선에 인접(incident)한 정점이다.

<br>

MST 문제를 설정해보자.  
- Input: Connected, Undirected Graph $`G = (V< E)`$, 가중치 함수 $`w: E \rightarrow \mathbb{R}`$  
- 목표: MST를 찾는 것이다.  

<br>

MST를 Generate하는 Algorithm을 Pseudo Code로 나타내면 다음과 같다:  
```python
1   A = ∅
2   while A does not form a spanning tree:
3       find an edge (u, v) that is safe for A
4       A = A ∪ {(u, v)}
5   return A
```
- Loop Invariant: $`A`$는 어떤 MST의 부분집합이다.  
- Initialization: $`A = \emptyset`$은 Loop Invariant를 이미 만족한다.  
- Maintenance: Safe Edge만 $`A`$에 추가한다.  
- Termination: 모든 간선이 고려되었을 때 Loop가 끝난다.  

<br>

Safe Edge는 어떻게 찾을까?  
<img src="Docs/Pasted image 20250708133005.png" width="300">
  
- 어떤 정점 집합 $`S \subset V`$를 고려: $`h \in S, g \notin S(g\in V-S)`$  
- MST는 항상 $`S`$와 $`V - S`$ 사이를 연결하는 적어도 하나의 간선을 가져야 한다.  
- 이 간선들 중 가중치가 가장 작은 것을 선택하면 MST에 포함되어야만 하는 간선이 된다.  
- 이 경우 그 간선은 $`(h, g)`$이다. $`\rightarrow`$ Safe Edge  

<br>

#### Definitions  

<br>

일종의 Greedy Algorithm을 적용해도 될지 정당화하는 과정이다.  
정의가 많이 나오지만 집중해서 한 번 봐보자.  

<br>

<img src="Docs/Pasted image 20250708133825.png" width="450">
  

<br>

| 용어             | 설명                                             | 그림               |  
| -------------- | ---------------------------------------------- | ---------------- |  
| Cut $`(S, V-S)`$ | 정점 집합 $`V`$ 를 $`S`$ 와 $`V-S`$ 둘로 나눈 것                | 빨간 선             |  
| Crosses        | 간선이 두 집합을 연결할 때                                | 빨간 선을<br>지나는 간선들 |  
| Respects       | $`A`$(현재까지 선택한 간선들)의 간선들이 Cut을 넘지 않으면            | 파란 간선            |  
| Light Edge     | Cut을 넘는 간선들 중 최소 가중치를 가지는 간선                   | $`(d, c)`$         |  
| Safe Edge      | 어떤 MST에 반드시 포함될 수 있는 간선                        | -                |  
| 핵심 정리          | Cut이 $`A`$를 Respects한다면 Light Edge는 Safe Edge이다. | -                |  

<br>

$`\S Theorem`$
> Let $`A`$ be a subset of some MST, and let $`(S, V - S)`$ be a cut that respects $`A`$. Let $`(u, v)`$ be a **light edge** crossing the cut.   
> Then, $`(u, v)`$ is **safe** for $`A`$.    
- 즉, MST를 구성하는 데 있어 안전하게 추가해도 된다는 뜻이다.  

<br>

$`(Proof)`$
$`A`$를 어떤 MST $`T`$의 부분집합이고, Cut이 $`A`$를 Respect 한다고 하자.
$`(u, v)`$는 Light Edge이지만 아직 $`T`$에 포합되어 있지 않다고 가정하자.
$`T`$는 $`S`$와 $`V-S`$를 연결하므로 반드시 다른 간선 $`(x, y)`$가 Cut을 건너야 한다.
그러나 $`(u, v)`$는 더 가벼운 간선이므로 $`(x, y)`$를 $`(u, v)`$로 바꾸면 더 작은 Tree가 발생한다. $`\downarrow`$  
따라서 $`(u, v)`$는 반드시 MST에 포합되어야 하므로 Safe Edge이다.  

<br>

MST의 Algorithm의 일반적인 틀은 다음과 같다.  
1. $`A`$: MST의 부분 집합으로 초기화  
2. Cut: $`A`$를 Respects 하는 Cut을 정의  
3. Light Edge: Cut을 건너는 가장 가벼운 간선 선택  
4. 추가: 해당 간선을 $`A`$에 추가  
반복하여 $`A`$가 Spanning Tree가 되면 그것이 MST이다.  

<br>

Kruskal's Algorithm:  
- 명시적으로 Cut을 구성하지는 않지만 매 단계마다 Safe Edge를 찾는다.  
- 서로소 집합 구조로 Cycle이 생기지 않게 하며 최고 간선을 선택한다.  
Prim's Algorithm:  
- $`S`$를 점차 확장되는 연결된 정점 집합으로 보고,  
- 매번 $`S`$에서 $`V-S`$로 가는 가장 가벼운 간선을 선택한다. (Light Edge)  

<br>

## 10.2 Kruskal's Algorithm  

<br>

**Kruskal's Algorithm**:  
1. 각 정점을 자기 자신의 컴포넌트로 시작한다. 처음에는 모든 정점이 독립적이다.  
2. 간선을 가중치 오름차순으로 정렬한다.  
3. Light Edge를 하나씩 선택하여 서로 다른 컴포넌트를 연결하는 경우에만 합친다. (Cycle 방지)  
4. Disjoint Set을 이용해 간선이 서로 다른 컴포넌트를 연결하는지 확인한다.  
여기서 컴포넌트란 Graph를 말그대로 "조각 조각" 낸 것으로, 제일 작게는 정점 1개씩까지 쪼갤 수 있다.  

<br>

#### Recap: Disjoint Set  

<br>

Disjoing Set은 CSE3080(자료구조)에서 배웠을 것이다.  
한 번 다시 상기하고 넘어가자.  

<br>

Disjoint Set: 서로 겹치지 않는 여러 집합의 모음  
- 각 집합은 대표값(Representative)를 가지고 있다.  
- 대표값은 집합을 식별하는 기준이며, 내부 요소 중 하나를 선택한다.  

<br>

Disjoint Set의 주요 Operation 3가지는 다음과 같다:  
1. `MAKE-SET(x)`: $`x`$를 원소로 하는 새로운 집합 생성, $`\mathcal{S}`$에 추가  
2. `UNION(x, y)`: $`x`$와 $`y`$가 각각 속한 집합을 합친다. 둘 중 하나의 대표값이 선택된다.  
3. `FIND-SET(x)`: $`x`$가 속한 집합의 대표값을 반환한다.  

<br>

`자세한 동작과 코드는 17p. 참고`  

<br>

Kruskal's Algorithm을 Pseudo Code로 나타내면 다음과 같다:  
```python
1   A = ∅
2   for each vertex v ∈ G.V
3       MAKE-SET(v)    # Disjoin Set Initializing
4   create a single list of the edges in G.E
5   sort the list of edges into monotonically increasing order by weight w  # 오름차순
6   for each edge (u, v) taken from the sorted list in order
7       if FIND-SET(u) ≠ FIND-SET(v)
8           A = A ∪ {(u, v)}
9           UNION(u, v)
10  return A
```
- 시간 복잡도: $`O(E \lg V)`$  
- Disjoint Set Initializing $`O(|V|)`$  
- 오름차순 정렬 $`O(E \lg V)`$  

<br>

`추가 정리 및 이해 필요 23p.`  

<br>

## 10.3 Prim's Algorithm  

<br>

**Prim's Algorithm**:  
1. 시작: 임의의 정점 $`r`$을 선택하여 시작한다.  
2. 초기화: 시작 정점 $`r`$만을 포함하는 집합 $`A`$를 만든다.  
3. 반복:  
- $`A`$와 아직 포합되지 않은 정점을 연결하는 Light Edge를 선택한다.  
- 해당 간선과 정점을 $`A`$에 추가한다.  
4. 종료: 모든 정점이 포함되면 $`A`$는 MST이다.  

<br>

#### Recap: Miminum Priority Queue  

<br>

Minumum Priority Queue의 주요 Operation 4가지를 정리하면 다음과 같다:  
- `INSERT(S, x, k)`: 키 $`k`$로 원소 $`x`$ 삽입, $`O(\lg n)`$  
- `EXTRACT-MIN(S)`: 최소 키를 가진 원소 제거 및 반환, $`O(\lg n)`$  
- `DECREASE-KEY(S, x, k)`: $`x`$의 키를 $`k`$로 감소 $`O(\lg n)`$  
- `MINIMUM(s)`: 최소 키 조회, $`\Theta(1)`$  

<br>

Light Edge를 빨리 찾는 방법으로 Priority Queue $`\mathcal{Q}`$를 채택하였다.  
- Queue $`\mathcal{Q}`$: 아직 $`A`$에 포함되지 않은 정점들  
- $`v.key`$: $`A`$에 있는 정점들과 연결되는 간선 중 최소 가중치  
- $`v.\pi`$: $`A`$에 존재하는 $`v`$의 부모 정점. 즉, Queue에 있는 모든 정점들의 부모는 이미 $`A`$에 있다.  
- $`A = \{ (v, v.\pi): v \in V - \{ r \} - \mathcal{Q} \}`$  
즉, MST는 다음과 같다. $`A = \{ (v, v.\pi): v \in V - \{ r \} \}`$  

<br>

Prim's Algorithm의 Pseudo Code는 다음과 같다:  
```python
MST-PRIM(G, w, r)
1   for each vertex u ∈ G.V
2       u.key = ∞
3       u.π = NIL
4   r.key = 0
5   Q = ∅
6   for each vertex u ∈ G.V
7       INSERT(Q, u)           # 모든 정점을 key 값(w) 기준으로 삽입
8   while Q ≠ ∅
9       u = EXTRACT-MIN(Q)     # 가장 가벼운 정점 u 선택 (A에 추가)
10      for each vertex v in G.Adj[u]    # u의 인접 정점들 확인
11          if v ∈ Q and w(u, v) < v.key
12              v.π = u
13              v.key = w(u, v)          # Key 값을 갱신하고, 부모 포인터를 u로 설정
14              DECREASE-KEY(Q, v, w(u, v))
```
- 시간 복잡도: $`O(E + V \lg V)`$  
- `자세한 설명은 생략하셨다.`  

<br>

# 11. Single-Source Shortest Paths  

<br>

## 11.1 Shortest Paths  

<br>

Shortest Paths는 두 정점 사이의 최단 경로를 구하는 문제이다.  
- Input:  
- Directed Graph $`G = (V, E)`$  
- Weight Function $`w : E \rightarrow \mathbb{R}`$  
- $`\delta(u, v)`$: 정점 $`u`$에서 $`v`$로 가는 최단 경로의 가중치 함
<br>


```math
\delta(u, v) = \begin{cases} \min\{w(p) : u \rightsquigarrow v\} & \text{if path exists} \\ \infty & \text{otherwise} \end{cases}
```

- 최단 경로는 당연하지만 유일하지 않을 수 있다.  

<br>

$`Lemma`$
- 어떤 최단 경로의 Subpath도 최단 경로이다.  
- $`(Proof)`$: Cut-and-Paste  

<br>

그렇다면 간선 중에 Negative-Weight(음수 간선)나 Cycle이 있으면 어떡할까?  
- Negative-Weight O, Cycle X: 무한히 돌면서 $`-\infty`$ 까지 줄일 수 있기 때문이다.  
- 하지만 Negative-Weight Cycle이 있어도 출발점(Source)에서 도달 불가능하면 괜찮다.  
- 어떤 알고리즘은 Negative-Weight가 있어도 괜찮다. e.g. Bellman-Ford  
- 어떤 알고리즘은 Negative-Weight가 있으면 안된다. e.g. Dijkstra  

<br>

즉, 최단 경로는 Cycle을 포함하지 않는다:  
- Negative-Weight Cycle X  
- Positive-Weight Cycle X `빼면 더 작아짐`  
- 0-Weight Cycle X `쓸 이유가 없음`  

<br>

Shortest Path의 $`v \in V`$의 두 가지 주요 값은 다음과 같다:  
1. $`v.d`$: Shortest-Path Estimate, $`s`$에서 $`v`$까지의 현재까지 알려진 최단 경로 거리 추정치  
- 초기에는 $`v.d = \infty`$  
- 항상 $`v.d \ge \delta(s, v)`$  
2. $`v.\pi`$: 정점 $`v`$로 가는 최단 경로에서의 직전 정점  
- 없으면 $`v.\pi = \text{NIL}`$  
- Shortest-Path Tree를 구성 가능하다.  

<br>

`INITIALIZE-SINGLE-SOURCE(G, s)`: 모든 최단 경로 알고리즘은 이 함수로 시작한다.  
```python
INITIALIZE-SINGLE-SOURCE(G, s)
1	for each vertex v ∈ G.V:
2	    v.d = ∞
3	    v.π = NIL
4	s.d = 0
```

<br>

<img src="Docs/Pasted image 20250709133245.png" width="300">
  
`RELAX(u, v, w)`: 간선 $`(u, v)`$를 통해 $`v`$에 대한 더 짧은 경로가 발견될 수 있을 때 이를 업데이트 한다.  
```python
RELAX(u, v, w)
1	if v.d > u.d + w(u, v):
2	    v.d = u.d + w(u, v)
3	    v.π = u
```

<br>

모든 Single-Source Shortest-Path 알고리즘은:  
1. `INITIALIZE-SINGLE-SOURCE()`를 먼저 호출  
2. 이후에 간선들을 Relax  
차이점은 relax를 어떤 순서로, 몇 번 반복하는가에 있다. (e.g. Dijkstra는 매 간선을 1번, Bellman-Ford는 여러 번)  

<br>


<br>

Single-Source Shortest-Path의 수학적 특성들은 다음과 같다:  

<br>

| 성질                           | 설명                                                                                                                                      |  
| ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |  
| **Triangle Inequality**      | $`\delta(s,v) \leq \delta(s,u) + w(u,v)`$                                                                                                 |  
| **Upper-Bound Property**     | 항상 $`v.d \geq \delta(s,v)`$이고, 한 번 $`v.d = \delta(s, v)`$가 되면 더 줄어들지 않는다.                                                                   |  
| **No-Path Property**         | $`\delta(s,v) = \infty`$ 이면 $`v.d = \infty`$                                                                                                |  
| **Convergence Property**     | $`s \rightsquigarrow u \rightarrow v`$가 최단 경로이고 Relax하면 $`v.d = \delta(s,v)`$                                                               |  
| **Path-relaxation Property** | 최단 경로상의 간선들을 순서대로 Relax하면 정확한 거리, 즉 $`v_k.d = \delta(s, v_k)`$ 도출 가능<br>그러나 경로 상의 간선을 반드시 연속적으로 Relax 할 필요는 없고, 다른 간선들의 Relax가 끼어있어도 괜찮다. |  

<br>

## 11.2 Bellman-Ford Algorithm  

<br>

**Bellman-Ford Algorithm**:  
- Negative-Weight 간선 허용  
- 단일 출발점 `s`에서 모든 정점 `v`에 대해 최단 거리 `v.d`와 경로 추적을 위한 `v.π`계산  
- Negative Cycle이 존재하지 않을 경우 `TRUE` 반환, 존재할 경우 `FALSE` 반환  

<br>

Bellman-Ford Algorithm의 Pseudo Code는 다음과 같다:  
```python
BELLMAN-FORD(G, w, s)
1   INITIALIZE-SINGLE-SOURCE(G, s)
2   for i = 1 to |G.V| - 1:
3       for each edge (u, v) ∈ G.E:
4           RELAX(u, v, w)
5   for each edge (u, v) ∈ G.E:
6       if v.d > u.d + w(u, v)
7           return FALSE    # 음수 사이클 존재
8   return TRUE             # 성공적으로 모든 최단 경로 계산
```
- 시간 복잡도: $`O(V^2 + VE)`$  
- $`|V| - 1`$번 반복 $`\times`$ 매 반복마다 모든 간선 검사 $`\Theta(V+E)`$  

<br>

## 11.3 Dijkstra's Algorithm  

<br>

**Dijkstra's Algorithm**  
- Negative-Weight 간선을 허용하지 않는다.  
- 가중치가 있는 BFS처럼 생각할 수 있다. (BFS + Priority Queue)  
- Priority Queue를 이용해서 `v.d`(거리)가 가장 짧은 정점을 먼저 선택한다.  
- 최단 거리 값을 확정한 정점 집합: `S`  
- 아직 미확정이지만 후보인 정접 집합: `Q = V - S` (Priority Queue)  

<br>

Dijkstra's Algorithm의 Pseudo Code는 다음과 같다:  
```python
DIJKSTRA(G, w, s)
1   INITIALIZE-SINGLE-SOURCE(G, s)
2   S = ∅
3   Q = ∅
4   for each vertex u in G.V:
5       INSERT(Q, u)             # 모든 정점을 Queue에 넣고 시작
6   while Q ≠ ∅:
7       u = EXTRACT-MIN(Q)
8       S = S ∪ {u}
9       for each vertex v in G.Adj[u]:
10          RELAX(u, v, w)       # u의 인접 정점들 Relax하고,
11          if v.d decreased:    # 더 짧은 경로가 발견되면 Queue에서 우선순위 갱신
12              DECREASE-KEY(Q, v, v.d)
```
- 시간 복잠도: $`O(V\lg V + E)`$  

<br>

| 알고리즘                 | Output                                      |  
| -------------------- | ------------------------------------------- |  
| Dijkstra's Algorithm | Shortest Path                               |  
| Prim's Algorithm     | Minimum Spanning Tree                       |  
| 공통점                  | 둘 다 Priority Queue와 Greedy Algorithm을 사용한다. |  

<br>

Dijkstra's Algorithm의 정확성은 다음과 같이 귀납적으로 증명될 수 있다:  
- 알고리즘은 출발점 `s`로부터 최단 거리 순서로 Priority Queue 에서 정점을 추출한다.  
- 귀납적으로 알고리즘이 어떤 집합 `S`에 대한 최단 경로를 찾았다면,  
- `V - S`에서 가장 가까운 정점에 대한 최단 경로는 `S`의 어떤 정점에 단일 간선을 추가하여 찾을 수 있다.  

<br>

# 12. All-Pairs Shortest Path  

<br>

## 12.1 About All-Pairs Shortest Path(APSP)  

<br>

## 12.2 Solve APSP with Dynamic Programming  

<br>

앞서서는 Greedy로 풀었다. 하지만 여기선 DP로 한 번 풀어볼 것이다. APSP는 DP Framework에 적합한 구조를 띄고 있기 때문이다.  
Recap: DP의 과정  
1. 문제의 최적해 구조를 정의  
2. 재귀적으로 최적해의 값을 정의: 수식 또는 점화식으로 표현한다.  
3. 최적해의 값을 실제로 계산 (Bottom-Up): 작은 문제부터 차례대로 계산해서 Table에 저장한다.  
- Top-Down Divide and Conquer 풀듯이 자연스럽게 정의하는 것이고,  
- Bottom-Up은 작은 문제를 기반으로 더 큰 문제를 풀어나가며 Table을 채워나가는 것이다.  
4. 필요한 경우 해 자체를 구성: 최적해의 "값"만 필요한 경우 생략 가능한다.  
- 최적화된 값은 이건데, '어떤' 최적화 과정을 거쳤느냐가 궁금할 때  

<br>

### 12.2.1 `SLOW-APSP`  

<br>

(1) 그렇다면 DP의 과정에 따라 먼저 Optinal Substructure를 정의해보자.  

<br>

Recap: $`Lemma`$  
- "어떤 최단 경로의 Subpath도 최단 경로이다."  
- 이를 Cut-and-paste 방법으로 증명하는 것은 이미 Lecture 11에서 했었다.  

<br>

(2) 이 다음은 재귀적으로 최적해의 값을 정의할 순서이다.  

<br>

$`l^{(r)}_{ij}`$: 정점 $`i`$에서 $`j`$로 가는 최단경로 거리, 단 최대 $`r`$개의 간선만 사용가능하다.
이제 점화식을 정의해보자.  

<br>

- $`r = 0`$:
<br>


```math
l^{(0)}_{ij} = \begin{cases} 0 & \text{if } i = j \\ \infty & \text{if } i \ne j \end{cases}
```

- $`r \ge 1`$:
<br>


```math
\begin{align}
l^{(r)}_{ij} &= \min \left( l^{(r-1)}_{ij}, \min_{1 \leq k \leq n} \left( l^{(r-1)}_{ik} + w_{kj} : 1 \le k \le n \right) \right) \\
&= \min_{1 \leq k \leq n} \left( l^{(r-1)}_{ik} + w_{kj} : 1 \le k \le n \right)
\end{align}
```

- 이는 Relaxation의 개념과 유사하다.  

<br>

우리는 $`r = 1`$일 때, $`l^{(1)}_{ij} = w_{ij}`$임을 관찰할 수 있다.  
즉 경로에 최대 1개의 간선만 허용한다면, 최소 경로는 그냥 직접 연결된 간선의 가중치 $`w_{ij}`$이다.  

<br>

이제 점화식을 구현해보자.
<br>

$`L^{(1)} = W,`$ 즉 Adjacency Matrix로 시작하자.
- 점점 더 많은 간선을 허용하며 $`L^{(2)}, L^{(3)}, ..., L^{(n-1)}`$까지 확장한다.  

<br>

핵심 함수가 되는 `EXTEND-SHORTEST-PATHS`의 Pseudo Code는 다음과 같다.  
```python
EXTEND-SHORTEST-PATHS(L^{(r-1)}, W, L^{(r)}, n)
1   # L^{(r)}의 원소들은 처음에 ∞로 초기화 되어있다고 가정한다.
2	for i = 1 to n
3	  for j = 1 to n
4	    for k = 1 to n
5	      l^{(r)}_{ij} = min(l^{(r)}_{ij}, l^{(r-1)}_{ik} + w_{kj})
```
- 각 단계에서, 간선 수를 하나 늘리며 가능한 모든 경로를 고려하여 최단 거리를 업데이트한다.   
- 시간 복잡도: $`\Theta(n^3)`$  

<br>


```math
l^{(r)}_{ij} = \min_{1 \leq k \leq n} \left( l^{(r-1)}_{ik} + w_{kj} \right)
```


<br>

이는 Matrix Multiplication과 매우 유사하다.  
표준 행렬곱 $`c_{ij} = \sum_{k=1}^n a_{ik} \cdot b_{kj}`$ 관계를 다음과 같이 대입하면:       
- $`l^{(r-1)} \to a`$  
- $`w \to b`$   
- $`l^{(r)} \to c`$   
- $`\min \to +`$  
+ $`+ \to \cdot`$  
그러면 min-plus 세상에서는 일반 곱셈이 최솟값(min)으로, 덧셈이 더하기(+)로 바뀐다.  
이는 추상수학의 일종으로, 일단 이렇게 정의 되어있다 정도만 파악하면 될 것 같다.  

<br>

따라서 우리가 만든 점화식을 일반 행렬곱처럼 다음과 같이 다시 바꿀 수가 있다.  
```cpp
2	for i = 1 to n
3	  for j = 1 to n
4	    for k = 1 to n
5	      c_{ij} = min(c_{ij}, a_{ik} + b_{kj})
```

<br>

알고리즘: `SLOW-APSP(W, L^(0), n)`  
```python
1   L = L^(0)
2   for r = 1 to n-1:
3       M = ∞      # 새로운 행렬 초기화
4       M = L · W  # min-plus 행렬곱
5       L = M
6   return L
```
- Adjacency Matrix $`W`$를 사용해 점차 확장된 최단경로 행렬 $`L`$을 얻는다.  
- 이때 $`L^{(r)} = L^{(r-1)} \cdot W`$, 즉 min-plus 행렬곱 연산을 반복한다.  
- 시간 복잡도: $`\Theta(n^4)`$  

<br>

<img src="Docs/Pasted image 20250710134855.png" width="600">
  
- 각 단계 $`L^{(r)}`$ 행렬은 다음을 의미한다.  
- $`L^{(1)}`$: 직접 연결된 간선 가중치 (W)  
    - $`L^{(2)}`$: 최대 2개의 간선을 이용한 최단거리  
    - $`L^{(3)}, L^{(4)}`$: 점점 경로 확장  
- $`L^{(r)} = L^{(n-1)} \quad \text{for all } r \geq n - 1`$  
- 경로에 최대 $`n-1`$개의 간선만 사용하면, 더 이상 최단거리가 바뀌지 않는다.  

<br>

### 12.2.2 `FASTER-APSP`  

<br>

일단 여기까지만 보면 딱히 성능의 개선은 보이지 않는다.  
그렇다면 어떻게 시간 복잡도를 줄여나가야 할까?  
- 최종적으로 구하고 싶은 것은 $`L^{(n-1)}`$인데,  
- 중간의 모든 $`L^{(1)}, L^{(2)}, \dots, L^{(n-2)}`$를 전부 계산할 필요는 없다는 것이 주요 아이디어다.  

<br>

반복 행렬곱 (Matrix Power)  
- 아래와 같이 $`W`$의 거듭제곱 형태로 표현 가능:
<br>


```math
\begin{align}
L^{(1)} &= W, \\ 
L^{(2)} &= W^2, \\
L^{(3)} &= W^3, \\
&\vdots \\
L^{(n-1)} &= W^{n-1} \\
\end{align}
```


<br>

개선된 알고리즘: 반복 제곱 (Repeated Squaring)  
- 일반적인 곱셈 대신 지수적 방식으로 행렬 제곱:
<br>


```math
\begin{align}
L^{(2)} = W^2 &= W \cdot W \\ 
L^{(4)} = W^4 &= W^2 \cdot W^2 \\ 
L^{(8)} = W^8 &= W^4 \cdot W^4 \\ 
&\vdots
\end{align}
```

- 마지막에 필요한 $`W^{n-1}`$을 얻기 위해서:   
```math
W^{n-1} = W^{2^{\lfloor \log_2 (n-1) \rfloor}} \cdot W^{2^{\lfloor \log_2 (n-1) \rfloor - 1}}
```
  
따라서 성능 개선이 된 `FASTER-APSP(W, n)`의 Pseudo Code는 다음과 같다.  
```python
FASTER-APSP(W, n)
1   let L and M be new n × n matrices
2   L = W
3   r = 1
4   while r < n - 1
5     M = ∞                   # M을 ∞로 초기화
6     EXTEND-SHORTEST-PATHS(L, L, M, n)   # M = L² (min-plus 곱)
7     r = 2 * r               # 반복 제곱을 위한 r 증가
8     L = M                  # 다음 반복을 위한 준비
9   return L
```
- 시간 복잡도: $`\Theta(n^3 \cdot \log n)`$  

<br>

## 12.3 Other Faster Algorithms  

<br>

### 12.3.1 Floyd-Warshall Algorithms  

<br>

Floyd-Warshall의 핵심 아이디어는 DP를 사용하여 접근하는 것이다.  
경로 $`p = \langle v_1, v_2, \ldots, v_l \rangle`$에서   
- intermediate vertex(중간 정점): 시작과 끝을 제외한 정점      
- $`d^{(k)}_{ij} = \text{정점 } \{1, 2, \ldots, k\} \text{까지만 중간 정점으로 허용했을 때, } i \to j \text{ 최단 거리}`$  

<br>

<img src="Docs/Pasted image 20250710140142.png" width="600">
  

<br>

중간 정점 $`k`$에 대한 케이스 분리  
1. $`k`$가 중간 정점이 아닌 경우:  
    - 모든 중간 정점은 $`\{1, \dots, k-1\}`$에 포함됨  
2. $`k`$가 중간 정점인 경우:  
    - 경로 $`i \to j`$는 $`i \to k \to j`$로 나눌 수 있으며,  
        - $`i \to k`$: $`\{1, \dots, k-1\}`$ 중간 정점만 포함  
        - $`k \to j`$: $`\{1, \dots, k-1\}`$ 중간 정점만 포함  

<br>

이제 점화식을 세워보자.  

<br>


```math
d^{(k)}_{ij} = \begin{cases} w_{ij} & \text{if } k = 0 \\ \min\left( d^{(k-1)}_{ij},\ d^{(k-1)}_{ik} + d^{(k-1)}_{kj} \right) & \text{if } k \geq 1 \end{cases}
```

- 즉, 중간 정점이 $`\leq k`$일 때, $`i \to j`$로 가는 최단 경로는  
    - $`k`$를 포함하지 않는 경로이거나  
    - $`i \to k \to j`$ 경로일 수 있다.  
- 초깃값 $`d^{(0)}_{ij} = w_{ij}`$: 중간 정점 없이 직접 연결된 가중치  
- 최종적으로 원하는 것: $`D^{(n)} = (d^{(n)}_{ij}) \Rightarrow \text{모든 중간 정점 사용 가능}`$  

<br>

이를 기반으로 한 `FLOYD-WARSHALL(W, n)`의 Pseudo Code는 다음과 같다:  
```python
FLOYD-WARSHALL(W, n)
1   D^(0) = W
2   for k = 1 to n
3     let D^(k) = new n x n matrix
4     for i = 1 to n
5       for j = 1 to n
6         d^(k)_{ij} = min(d^(k-1)_{ij}, d^(k-1)_{ik} + d^(k-1)_{kj})
7   return D^(n)
```
- 시간 복잡도: $`\Theta(n^3)`$  

<br>

**Computing Predecessors (선행 정점 추척)**  

<br>

최단 경로의 실제 경로 구성을 위해, 각 dijd_{ij}에 대해 "j의 직전 정점(predecessor)"을 기록하는 행렬 Π\Pi 계산  

<br>

초기화 ($`k = 0`$)  

<br>


```math
\pi_{ij}^{(0)} = \begin{cases} \text{NIL} & \text{if } i = j \text{ or } w_{ij} = \infty \\ i & \text{if } i \ne j \text{ and } w_{ij} < \infty \end{cases}
```

- 초기에는 직접 연결된 간선만 고려한다.  

<br>

점화식 ($`k \ge 1`$)
<br>


```math
\pi_{ij}^{(k)} = \begin{cases} \pi_{kj}^{(k-1)} & \text{if } d_{ij}^{(k-1)} > d_{ik}^{(k-1)} + d_{kj}^{(k-1)} \\ \pi_{ij}^{(k-1)} & \text{otherwise} \end{cases}
```

- 만약 $`k`$를 경유하면 더 짧은 경로가 생긴다면,    
- $`j`$의 Predecessor는 $`k`$를 거쳐 오는 경로의 끝이다, 즉 $`\pi_{kj}`$  

<br>

활용 `plus alpha`  
- 최단 거리뿐 아니라, 경로를 역추적하여 실제 경로를 복원할 수 있다.  
- e.g. $`\text{Print-Path}(i, j)`$ 호출 시, $`\pi[i][j]`$ 따라가면서 경로를 재귀적으로 복원 가능하다.  

<br>

### 12.3.2 Transitive Closure  

<br>

Transitive Closure의 목표는 다음과 같다:  
- Directed Graph $`G = (V, E)`$가 주어 졌을 때  
- Transitive Closure $`G^* = (V, E^*)`$를 계산하는 것이다.  

<br>

다음을 정의해보자.  
- $`(i, j) \in E^* \Leftrightarrow i \to j`$ 경로가 $`G`$에 존재한다.  
- 즉, 그래프에 직접 간선이 없어도 간접 경로로 도달 가능하면 포함한다.  

<br>

먼저 `FLOYD-WARSHALL`을 이용하는 방법이 있다.  
- 모든 간선 가중치를 1로 설정하고 Floyd-Warshall Algorithm을 실행한다.  
- $`d_{ij} < \infty \rightarrow`$ 경로 존재  
- $`d_{ij} = \infty \rightarrow`$ 경로 없음  
그러나 이는 연산량이 불필요하게 많다.  

<br>

따라서 나온 것이 논리 연산 (∨, ∧)으로 단순화하는 방식이다.  
- Unweighted Adjacency Matrix를 사용한다.  
- $`\min \rightarrow`$ ∨(OR)  
- $`+ \rightarrow`$ ∧(AND)  

<br>

$`t_{ij}^{(k)}`$는 다음과 같이 정의된다:
- $`t_{ij}^{(k)} = 1`$: 정점 $`i \to j`$로 가는 경로가 존재 (중간 정점은 $`\le k`$)  
- $`t_{ij}^{(k)} = 0`$: 경로 없음  

<br>

점화식은 다음과 같다.  

<br>

초기화 ($`k = 0`$):
<br>


```math
t_{ij}^{(0)} = \begin{cases} 1 & \text{if } i = j \text{ or } (i, j) \in E \\ 0 & \text{otherwise} \end{cases}
```

반복문 ($`k \ge 1`$):
<br>


```math
t_{ij}^{(k)} = t_{ij}^{(k-1)} \vee \left( t_{ik}^{(k-1)} \wedge t_{kj}^{(k-1)} \right)
```

- 즉, $`i \to j`$ 경로가 직접 있거나, 또는 $`i \to k \to j`$를 통해 간접적으로 있는가?  

<br>

이를 기반으로 한 `TRANSITIVE-CLOSURE(G, n)`의 Pseudo Code는 다음과 같다:  
```python
TRANSITIVE-CLOSURE(G, n)
1   let T^(0) = (t^(0)_{ij}) be a new n x n matrix
2   for i = 1 to n
3     for j = 1 to n
4       if i == j or (i, j) ∈ G.E
5         t^(0)_{ij} = 1
6       else
7         t^(0)_{ij} = 0

8   for k = 1 to n
9     let T^(k) = (t^(k)_{ij}) be a new n x n matrix
10    for i = 1 to n
11      for j = 1 to n
12        t^(k)_{ij} = t^(k-1)_{ij} ∨ (t^(k-1)_{ik} ∧ t^(k-1)_{kj})

13  return T^(n)
```
- 시간 복잡도: $`\Theta(n^3)`$, Floyd-Warshall과 동일하지만,  
- 연한은 논리 연산 (∨, ∧)으로 더 간단하고 빠르다.  

<br>

### 12.3.3 Johnson's Algorithm  

<br>

간선이 얼마 없을 때는 차라리 Dijkstra's Algorithm을 각 정점마다 적용하는 게 나을 수도 있으나, Negative-Weight 간선이 있을 때 Dijkstra를 사용할 수 없다는 것이 문제다.  
따라서 Johnson's Algorithm은 Negative-Weight 간선이 있어도 Dijkstra 알고리즘을 활용할 수 있도록 Reweighting(간선 재가중) 기법을 사용한다.  

<br>

#### Reweighting  

<br>

새로운 가중치 함수 $`\hat{w}(u, v)`$를 정의한다:  
1. 최단 경로 불변성 유지: $`\text{p is a shortest path with }w \Leftrightarrow \text{p is a shortest path with }\hat{w}`$  
2. 비음수화: $`\hat{w}(u, v) \ge 0 \quad \forall(u, v) \in E`$  

<br>

**(1) 최단 경로 불변성 유지 증명**  

<br>

$`Lemma`$
- "가중치 재조정은 최단 경로를 바꾸지 않는다."  

<br>

Graph $`G = (V, E)`$, 가중치 함수 $`w: E \rightarrow \mathbb{R}`$, 함수 $`h: V \rightarrow \mathbb{R}`$이 있다고 할 때,  
재정의된 가중치:
<br>


```math
\hat{w}(u, v) = w(u, v) + h(u) - h(v)
```

어떤 경로 $`p = \langle v_0, v_1, \dots, v_k \rangle`$에 대해:
<br>


```math
\hat{w}(p) = w(p) + h(v_0) - h(v_k)
```

- 즉, 경로의 가중치 순서는 유지된다.  

<br>

$`(Proof)`$

```math
\begin{align}
\hat{w}(p) &= \sum_{i=1}^{k} \hat{w}(v_{i-1}, v_i) \\
&= \sum_{i=1}^{k} (w(v_{i-1}, v_i) + h(v_{i-1}) - h(v_i)) \\
&= \sum_{i=1}^{k} w(v_{i-1}, v_i) + h(v_0) - h(v_k) \\
&= w(p) + h(v_0) - h(v_k)
\end{align}
```

- 재조정 후의 경로 가중치는 원래 경로 가중치에 일정한 상수만 더한 형태이므로 경로의 상대적 크기는 변하지 않는다.  
- $`\therefore`$ 최단 경로는 변하지 않는다.  

<br>

**(2) 비음수화 증명**  

<br>

그렇다면 위 조건을 만족하는 $`h(v)`$를 어떻게 계산할까?  
- 새로운 정점 $`s`$ 추가  
- $`G' = (V \cup \{s\}, E \cup \{(s,v) : v \in V\})`$  
- $`w(s,v) = 0`$  

<br>

그 다음,  
- Bellman-Ford 알고리즘으로 $`s \to v`$ 최단 거리 $`h(v) = \delta(s, v)`$ 계산  

<br>

$`Claim`$

```math
\hat{w}(u,v) = w(u,v) + h(u) - h(v) \ge 0
```


<br>

$`(Proof)`$
삼각 부등식 이용:
<br>


```math
\begin{align}
\delta(s, v) \le \delta(s, u) + w(u, v) \Rightarrow \\
h(v) \le h(u) + w(u,v) \Rightarrow \\
\therefore w(u,v) + h(u) - h(v) \ge 0
\end{align}
```

- 따라서 재조정된 가중치 $`\hat{w}`$는 항상 0 이상이다.  

<br>

`JOHNSON(G, w)`:  
```python
JOHNSON(G, w)
1   compute G′, where G′.V = G.V ∪ {s},
      G′.E = G.E ∪ {(s, v) : v ∈ G.V}, and
      w(s, v) = 0 for all v ∈ G.V
2   if BELLMAN-FORD(G′, w, s) == FALSE
3     print "the input graph contains a negative-weight cycle"
4   else
5     for each vertex v ∈ G′.V
6       set h(v) to the value of δ(s, v)  # shortest path from s using Bellman-Ford
7     for each edge (u, v) ∈ G′.E
8       ŵ(u, v) = w(u, v) + h(u) - h(v)
9     let D = (d_uv) new n × n matrix
10    for each vertex u ∈ G.V
11      run DIJKSTRA(G, ŵ, u) to compute ^δ(u, v) for all v ∈ G.V
12      for each vertex v ∈ G.V
13        d_uv = ^δ(u, v) + h(v) - h(u)
14    return D
```
- 시간 복잡도: $`O(V^2 \lg V + VE)`$  

<br>

# 13. NP Completeness and Approximation Algorithms  

<br>

좋은 알고리즘의 기준에는 효율성, 저확성, 실용성, 견고성, 확장성 등등이 있다.  
하지만 이 수업에서는 알고리즘의 시간 복잡도(Time Complexity)에 중점을 두고 논의했다.  
시간 복잡도 선호도:
<br>


```math
O(1) > O(\log n) > O(n) > O(n\log n) > O(n^2) > O(n^3) > O(2^n) > O(n!)
```

- $`O(n^3)`$까지가 Polynomial Time이라고 볼 수 있다.  
- 그 후로는 Exponential Time이다.  

<br>

## 13.1 NP Completeness  

<br>

우리는 지금까지 다양한 알고리즘 설계 기법을 배웠다:  
- Divide-and-conquer  
- Greedy algorithm  
- Dynamic programming  

<br>

우리가 배운 거의 모든 알고리즘은 다항 시간 알고리즘(Polynomial-Time Algorithm)이다:  
- 입력 크기 n일 때, 최악의 실행 시간은 일반적으로 $`O(n^k)`$ 형태 ($`k`$는 상수)  

<br>

그러나 모든 문제가 Polynomial Time 안에 풀수 있는 것은 아니다.  
e.g.  
- 튜링의 정지 문제(Halting Problem): 컴퓨터로 절대 풀 수 없는 문제  
- 풀 수는 있지만 어떤 $`k`$에 대해서도 $`O(n^k)`$ 시간으로는 풀 수 없는 문제도 있다.  

<br>

**Tractable vs Intractable**  
- Tractable: 다항 시간 안에 풀 수 있는 쉬운 문제  
- Intractable: 초다항 시간(Superpolynomial Time) 걸리는 어려운 문제  

<br>

우리가 배운 모든 알고리즘 기법을 써도 효율적으로 풀 수 없는 문제가 있으면 어떡할까?  
작은 입력에서는 잘 작동하지만, 큰 입력에서는 프로그램이 종료되지 않으면 어떡할까?  
> 알고리즘이 항상 정답을 줄 수 있는 것이 아니다. 심지어 완전히 작동하더라도, 입력이 커지면 현실적으로 실행이 불가능해지는 문제들이 있다.  

<br>

1960년대 후반, 많은 조합 최적화 문제들이 효율적으로 해결됐다:  
- 그러나 동시에 효율적인 알고리즘이 전혀 알려지지 않은 문제들도 생겨났다.  
- 그러던 중 매우 중요한 발견이 이루어졌다.  

<br>

NP-Completeness Problem은 다항 시간 알고리즘이 존재하지 않는다는 증거도 없고, 존재한다는 증거도 없다. 이 문제는 1971년부터 지금까지 컴퓨터 과학에서 가장 중요한 미해결 문제 중 하나이다.  
즉, $`P \neq NP`$ 의 질문은 여전히 미해결 문제이다.  
```
"모든 NP 문제를 다항 시간에 풀 수 있는가?" : P = NP ?
```

<br>

어떤 NP-Completeness Problem은 겉보기엔 쉽게 풀 수 있을 것 같지만, 실제로는 매우 어렵다.  
e.g. Shortest vs Longest Path  
- Shortest Path(최단 경로): 다항 시간에 풀 수 있다. (e.g. Bellman-Ford)  
- Longest Simple Path(최장 단순 경로): NP-Complete          
- 그래프에 Simple Path가 존재하는지만 확인하는 것조차도 NP-complete이다.  

<br>

#### Class P  

<br>

- Polynomial Time 내에 풀 수 있는(Solvable) 문제들의 집합이다.  
- 즉, 입력 크기를 n이라 할 때, 시간 복잡도가 $`O(n^k)`$인 알고리즘으로 풀 수 있는 문제들이다.  
- 우리가 지금까지 공부한 대부분의 문제는 Class P에 속한다.  

<br>

#### Class NP  

<br>

- Polynomial Time 내에 검증할 수 있는(Verifiable) 문제들의 집합이다.  
- Verifiable하다는 것은 정답(Certificate)이 주어진다면, 그것이 맞는지 다항 시간에 검증할 수 있다는 것이다.  

<br>

e.g. Hamiltonian Cycle Problem:  
- 문제: Undirected Graph $`G=(V,E)`$가 모든 정점을 한 번씩만 방문하는 Cycle을 갖는가?  
- 해답 후보(Certificate): 정점들의 순열  
- 주어진 순열이 실제 Hamiltonian Cycle인지 Verifying 하는 것은 다항 시간에 가능하다.  

<br>

Class P vs. Class NP  
포함 관계:  
- $`P \subseteq NP`$: 모든 P 문제는 NP에도 속한다.  
- 풀 수 있다는 건, 당연히 검증도 가능하다는 뜻이기 때문이다.    
열린 문제:  
- $`P = NP \ ?`$: 아직까지 증명되지 않았다.  
- 많은 사람들이 $`P \neq NP`$라고 추측하고 있긴하다.  

<br>

#### Class NPC  

<br>

NPC에 대한 비공식적 정의는 다음과 같다:  
- NP에 속하고, NP의 모든 문제보다 최소한 동일하거나 더 어려운 문제들  
- 즉, 가장 어려운 NP 문제들이라고 간주된다.  

<br>

핵심 명제:  
- 어떤 하나의 NP-Complete 문제라도 Polynomial Time 내에 풀 수 있다면, 모든 NP 문제가 Polynomial Time 내에 풀린다.  
    - 즉, NPC 문제 중 하나만 P로 증명되면, $`NP = P`$가 성립한다.  
- e.g. 많은 조합 최적화 문제들 (SAT, TSP, 3-CNF-SAT 등)이 NP-Complete  

<br>

지금까지 어떤 NP-Complete 문제도 다항 시간에 푸는 알고리즘이 발견된 적 없다.  
따라서 일반적으로 Intractable(비현실적으로 어려운) 문제로 간주된다.  
그러나 우리는 아직 $`P = NP`$ 인지 모르기에, 모든 NPC 문제도 Polynomial Time에 풀릴 수 있을 가능성은 있다.  

<br>

`16p. 금방 넘어감`  

<br>

#### NP-Completeness  

<br>

- NP-Complete 문제임을 보이는 것은 "**이 문제는 얼마나 어려운가**"에 대한 주장을 하는 것이다.  
- NP-Completeness를 증명할 때는 효율적인 알고리즘이 존재하지 않을 가능성을 보여주려는 것이지, 효율적인 알고리즘이 있다는 것을 보여주려는 것이 아니다.  

<br>

**Decision Problem vs. Optinization Problem**  

<br>

| Problem              | 설명                                                                                             |  
| -------------------- | ---------------------------------------------------------------------------------------------- |  
| Optimization Problem | 가능한 해 중에서 **가장 좋은 값**을 찾는 문제<br>e.g. Shortest-Path Problem<br>> u에서 v까지 가장 적은 수의 간선을 사용하는 경로는? |  
| Decision Problem     | 답이 "예/아니오"인 문제                                                                                 |  
- 대체적으로 Optimization Problem이 어렵다고 말 할 수는 있으나, 완전한 답은 아니다.  

<br>

NP-Completeness는 원래 Decision Problem에만 직접 적용된다.  
- 그리고 대부분의 Optimization Problem은 어떤 값을 기준(Bound)으로 정해두는 방식으로 Decision Problem으로 변환 가능하다.  
- e.g. Shortest-Path Problem  
- Decision Proble으로 변환: "u에서 v까지 간선 수가 최대 k인 경로가 존재하는가?"  

<br>

왜 Decision Problem으로 바꾸는가?  
- NP의 정의 자체가 "검증 가능한 문제"이므로, 예/아니오로 답할 수 있어야 한다.  
- 최적값을 직접 검증하는 건 어렵기에 조건을 주고 예/아니오로 묻는 방식이 NP에 적합하다.  

<br>

최적화 문제를 해결하기 어렵다는 것을 보이기 위해, 그것과 관련된 결정 문제를 이용할 수 있습니다.  
왜냐하면, 결정 문제는 최적화 문제보다 “더 쉽거나 같기 때문”이다.  
e.g. 예시  
- SHORTES-PATH 문제 (최적화 문제): 가장 짧은 경로를 구함  
- PATH 문제 (결정 문제): u → v로 k개 이하의 간선을 가진 경로가 존재하는가?  
- 최적화 문제를 풀 수 있다면, k와 비교해서 결정 문제도 쉽게 풀 수 있음.  

<br>

#### Reduction  

<br>

<img src="Docs/Pasted image 20250711134947.png" width="600">
  
문제 A -> 문제 B로 Reduction 한다는 것은:  
- 문제 A의 입력 $`\alpha`$를 다항 시간 내에 문제 B의 입력 $`\beta`$로 변환하고  
- A에 대한 답이 "Yes"이면 B도 "Yes", A가 "No"면 B도 "No"인 구조를 만드는 것이다.
<br>

 
```math
A \le_p B
```
  
- 문제 A를 다항 시간 안에 문제 B 로 바꿔서 문제 B의 답을 통해 문제 A의 답을 알 수 있으면,  
- 결국 A도 다항 시간에 풀 수 있는 것이 된다.  

<br>

NP-Completeness 증명  
1. 문제 A가 아주 어려워서 다항 시간 알고리즘이 없다고 알려져 있다.  
2. 문제 A를 문제 B로 다항 시간에 환산 가능하다고 하자.  
3. 그런데 문제 B가 다항 시간에 풀린다고 가정하면...  
    - A도 다항 시간에 풀리게 된다. $`\downarrow`$  
> 문제 A가 어려운 문제로 알려졌고, $`A \le_p B`$ 라면 -> B도 적어도 A만큼 어렵다!  

<br>

| NP-Complete 임을 보이는 방법                                                         |  
| ----------------------------------------------------------------------------- |  
| 1. 해당 문제는 $`\in`$ NP 임을 보인다.                                                    |  
| 2. 이미 알려진 NP-Completeness Problem으로부터<br>Polynomial Reduction Altorighm을 만든다. |  
| ⇒ 이 두 단계를 거치면, 새로운 문제도 NP-Complete임을 증명 가능하다.                                 |  

<br>

NP-Complete하다는 것은 곳 "어움의 상징"이라는 의미인데, 이를 증명하기 위해서는  
다른 NP-Complete Problem 문제로부터의 Reduction이 필요하다.  
즉, "처음으로 NP-Complete 임이 증명된 문제"가 반드시 필요하다는 뜻이다.  
- Circuit-SAT(Boolean Satistiability Problem): Cook-Levin 정리에 의해 NP-Complete임이 증명되었다.  

<br>

그러나 왜 기반이 성립됐음에도 불구하고 많은 이들이 $`P \neq NP`$라고 믿을까?  
단 하나의 NP-Complete 문제라도 다항 시간 내에 풀린다면 모든 NP 문제가 다항 시간 내에 풀릴 수 있으나, 여전히 그 누구도 그런 알고리즘을 찾지 못했기 때문에 대부분의 사람들이 $`P \neq NP`$라고 믿는 것이다.  

<br>

**Polynomial-Time Reducibility(다항 시간 환산)**  
- NP-Complete 문제들은 Class NP 내에서 가장 어려운(Hardest) 문제들로 간주된다.  
- 여러 문제들의 상대적인 어려움을 비교할 수 있는 도구가 Polynomial-Time Reducibility(다항 시간 환산)이다.  
- 이 개념을 통해 수많은 문제들이 NP-Complete임을 차례로 증명할 수 있다.  

<br>

`27p. 넘어감`  

<br>

| 용어              | 정의                                                                 |  
| --------------- | ------------------------------------------------------------------ |  
| **NP-Hard**     | 모든 NP 문제를 다항 시간에 환산할 수 있는 문제. (즉, 이 문제를 풀 수 있다면 모든 NP 문제를 풀 수 있다.) |  
| **NP-Complete** | (1) NP에 속하고, (2) NP-Hard한 문제. 즉, NP 안에서 가장 어려운 문제들                 |  

<br>

문제 A가 NP-Complete가 되려면:  
- It is NP: $`A\in NP`$ `Verifying이 다항 시간에 가능`  
- It is NP-Hard:  
- 모든 NP 문제 $`A'`$에 대해 $`A' \le_p A`$  
- 또는 이미 NP-Complete임이 알려진 문제 $`A''`$에 대해 $`A'' \le_p A`$  
이 환산 관계를 통해 새로운 문제도 NP-Complete 임을 증명 가능하다.  

<br>

아래는 NP-Complete 문제들의 환산 Chain을 시각화한 구조도이다.  
<img src="Docs/Pasted image 20250711140446.png">
  

<br>

## 13.2 Approximation Algorithms  

<br>

NP-Complete문제의 최적화 버전은 중요해서 무시할 수 없으나, 풀기엔 너무 어렵다.  
이럴 땐 어떻게 해야 할까? 대응 전략으로는 다음 3가지가 있을 수 있겠다.  
1. 작은 입력에만 Exponential Time이지만 최적인 알고리즘을 사용 `비효율적이지만 정확하다`  
2. 특수한 경우에만 Polynomial Time 알고리즘을 설계  
3. **Approximation Algorithm**: 최적은 아니지만 충분히 괜찮은 근사 해를 구한다.  

<br>

일단, NP-Complete 문제는 본질적으로 모두 Decision Problem이다.  
즉 Class NP에는 Optimization Problem이 포함되지 않는다는 이야기다.  
e.g. Vertex-Cover Problem:  
- Decision Problem: Graph $`G`$ 에서 크기 $`\le K`$ 인 Vertex Cover가 존재하는가?  
- Optimizaiton Problem: 최소 크기의 Vertex Cover를 찾아라.  
> Approximation Algorithm은 Decision Problem이 아닌 Optimization Problem에 대해서 사용된다.  

<br>

Approximation Algorithm의 성능 평가 기준은 "얼마나 최적에 가까운가?" 이다.  
문제는 Maximization Problem이 될 수도, Minimization Problem이 될 수도 있다.  
- 입력 크기 $`n`$일 때:  
- Approximation Algorithm의 Solution Cost: $`C`$  
- Optimal Solution Cost: $`C^*`$  
- Performance Ratio:
<br>


```math
\max\left(\frac{C}{C^*}, \frac{C^*}{C}\right) \leq \rho(n)
```

이 알고리즘을 $`\rho(n)`$-Approximation Algorithm이라고 부른다.
<br>

$`\rho(n)`$은 입력 크기에 따라 달라질 수 있는 성능한계이다.

<br>

문제가 Maximization Problem이느냐 Minimization Problem이느냐는 성능 측정 지표에 별 상관은 없다.  
- Maximization Problem: $`0 < C \le C^* \rightarrow \frac{C^*}{C} \ge 1`$  
- Minimization Problem: $`0 < C^* \le C \rightarrow \frac{C}{C^*} \ge 1`$  

<br>

여기서 1-Approximation Algorithm($`C = C^*`$)은 항상 최적 해를 반환한다.  
- $`\rho(n)`$이 작을수록 성능이 좋고,  
- $`\rho(n)`$이 클수록 해가 최적 해보다 훨씬 나쁠 수 있다.  

<br>

그런데 이 모든 것이 성립하려면 최적 해가 존재해야 하는건데,  
애초에 최적 해를 구하기 위해 Approx를 하는 건데 이게 무슨 모순인가?  
이에 대한 답을 해보자면 최적 해를 직접 구해서 비교하는 것이라기 보다는,  
알고리즘을 설계하는 과정에서 최적 해와의 관계를 정립할 수 있다. `뭔소린지`  

<br>

#### Vertex-Cover Problem  

<br>

Vertex-Cover Problem의 정의는 다음과 같다:  
- Input: Undirected Graph $`G = (V, E)`$  
- Output: 최소 크기의 정점 집합 $`V' \subseteq V`$, 모든 간선이 $`V'`$에 속한 정점 중 적어도 하나와 연결되어 있어야한다.  
즉, 모든 간선을 "덮는(Cover)" 정점들의 최소 집합을 구하는 문제이다.  

<br>

이 문제에 대한 최적 알고리즘은 없으나, Approximation Algorithm은 존재한다.  
이 `APPROX-VERTEX-COVER(G)`의 Pseudo Code는 다음과 같다.  
```python
APPROX-VERTEX-COVER(G)
1   C = ∅    # Cover 집합
2   E` = G.E  # 아직 덮지 않은 간선들
3   while E` ≠ ∅
4       let (u, v) be an arbitrary edge of E'
5       C = C ∪ {u, v}
6       remove from E` edge (u, v) and every edge incident on either u or v
7   return C
```
- 매 Loop 마다 하나의 간선을 골라 양 끝 정점 둘 다 Cover 집합 $`C`$에 포함한다.  
- 간선을 빠르게 덮되, 최적과는 다를 수 있다.  
- 시간 복잡도: $`O(V + E)`$ `Adjaency List를 기준으로`  

<br>

<img src="Docs/Pasted image 20250711144455.png" width="450">
  
- 언뜻 보기엔 Approx Algorithm이 별로긴하다.  

<br>

**Analyze Performance Ratio**  

<br>

$`C^*`$: Optimal Vertex Cover
$`A`$: `APPROX-VERTEX-COVER`이 선택한 간선 목록

<br>

(1) Performance Ratio Lower Limit  
- $`A`$는 서로 겹치지 않는 간선들이다.  
- 따라서 $`C^*`$는 이 간선들을 덮기 위해 최소 $`|A|`$개의 정점을 필요로한다. 즉,
<br>


```math
|C^*| \ge |A|
```


<br>

(2) Performance Ratio Upper Limit  
- `APPROX-VERTEX-COVER`은 각 간선마다 양 끝점을 모두 C에 넣는다.
<br>


```math
|C| = 2|A|
```

- 따라서 (1)의 Lower Limit과 결합하면 Upper Limit은 다음과 같이 계산된다.
<br>


```math
|C| = 2 |A| \le 2|C^*|
```


<br>

> 따라서 `APPROX-VERTEX-COVER`는 항상 최적 해의 최대 2배 이하의 해를 반환하므로,  
> **2-Approximation Algorithm**이다.  

<br>


<br>
